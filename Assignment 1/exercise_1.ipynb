{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Assignment 1: Deadline: first class in week 4 of the course: 25-2-2025 10:00 (if updated).\n",
    "Hand in this notebook with output. Make sure that it is able to run and produce all the figures and results you show. Also, use the text boxes to answer the questions and interpret your results, relating them to the course materials.\n",
    "\n",
    "\n",
    "Exercises made by Oliver Gurney-Champion. Please contact us via Canvas, or e-mail directly to:\n",
    "Oliver: o.j.gurney-champion@amsterdamumc.nl\n",
    "Matthan: m.w.a.caan@amsterdamumc.nl\n",
    "Dilara: d.tank@amsterdamumc.nl\n",
    "Daan: d.kuppens@amsterdamumc.nl\n",
    "\n",
    "These are a large set of challenging exercises, for which you will get 3 weeks to complete. I would strongly advise you to stick to the suggested schedule, which will ensure you have sufficient knowledge to answer the questions when completing them, and finalize all questions in time.\n",
    "\n",
    "Note that the networks will be lite and can run on your local computer/laptop in short time (minutes). There is no need as yet to run this on Surf, although we highly encourage you to make sure Surf works for you (for exercise sets 2 and 3).\n",
    "\n",
    "# Exercise 1: Program network in PyTorch. (60%)\n",
    "During the class, a brief introduction was given to quantitative imaging. In this exercise, you will program your first neural network that will help estimate quantitative MRI parameters from quantitative data. In particular, we will be looking at the intra-voxel incoherent motion (IVIM) model for diffusion-weighted MRI:\n",
    "\n",
    "S(b)=S_0×( (1-f)×e^-b×D^ +f×e^-b×D*^ )                                                                    [1]\n",
    "\n",
    "With S the measured signal, S0 the baseline signal at S(b=0), f the perfusion fraction, D the diffusion coefficient and D* the pseudo diffusion coefficient. For more information on what the model means exactly and how it is used clinically, I would suggest reading \"Introduction to IVIM MRI | Radiology Key\" (https://radiologykey.com/introduction-to-ivim-mri/). But for the purpose of this exercise, it is just a model.\n",
    "\n",
    "Normally, f, D and D* (named Dp in the code) are obtained by fitting S(b) using least-squares fitting. But these approaches are known to be prone to noise in the data and often produce poor estimates.\n",
    "\n",
    "Therefore, you will write a neural network that predicts f from a given S(b). There are great tools available that take care of training models, such as PyTorch, Karas and Tensorflow. However, for the purpose of this exercise, you will make use of PyTorch. Moreover, we will use weights-and-biasses to keep track of how training is going.\n",
    "\n",
    "# Wednesday 3-4-2024\n",
    "At https://github.com/oliverchampion/AI_for_medical_imaging_course you will find the Python assignment. To help visualize progress and to isolate certain snippets of code, we wrote this as a Jupyter Notebook (exercise1.ipynb). As you can see, we have already provided a data-generator, some plotting tools to plot the training progress. The notebook should run as is and train a neural network! For your first lecture, we suggest you (Wednesday)\n",
    "-\tInstall all prerequisites in your virtual enviroment (requierements.txt)\n",
    "-\tStart a WandB account @ https://wandb.ai/  you will need to log in when running the script\n",
    "-\tGo through the script to see whether you understand what happens.\n",
    "-\tTrain your first neural network .\n",
    "-\tVisualize the results on your WandB page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import requiered packages\n",
    "imports the packages and sets the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "import helper_functions as hf\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# set random seed\n",
    "seed =42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "login to your free wandb account. Note you will need to set up your account on https://wandb.ai/authorize\n",
    "wandb allows you to keep track of your neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_SILENT=True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "%env WANDB_SILENT=True\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Simulate and view the IVIM data\n",
    "This allows you to study what the data looks like in jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c5f61152b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set b-values at which we \"measure\" (i.e. simulate signal)\n",
    "bvalues=[0, 10, 20, 30, 40, 50, 75, 100, 150, 250, 400, 600]\n",
    "\n",
    "## Set the random seeds for reproducibility\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "## Loading the (simulated) dataset\n",
    "data_sim, D, f, Dp = hf.sim_signal(SNR=(10,30),bvalues=bvalues,sims=30,seed=np.random.randint(1,10000))\n",
    "\n",
    "## plotting some curves and data for visualisation\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axs[i, j].plot(bvalues, data_sim[i+10*j,:], 'o')\n",
    "        datapred=hf.ivim(np.arange(0,np.max(bvalues)), D[i+10*j], f[i+10*j], Dp[i+10*j], 1)\n",
    "        axs[i, j].plot(np.arange(0,np.max(bvalues)), datapred)\n",
    "        axs[i, j].set_ylim(0, 1.2)\n",
    "        axs[i, j].set(xlabel='b-value (s/mm2)', ylabel='normalised signal')\n",
    "plt.legend(('noisy data', 'true curve'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Splitting the data into training and validation\n",
    "Here, we split our data into a training set, validation set and test set. Note that the current implementation only uses the training set and it is up to you (in your exercises) to also implement the validation and test run. At this point, we already split the data for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1c5f94197f0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1c5fb355bd0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1c5fb356210>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sim_dat(bvalues,batch_size = 16,SNR=(10,40),sims=1000,seed=np.random.randint(1,10000)):\n",
    "    with wandb.init(project=\"AI_for_medical_imaging\", job_type=\"visualize data\") as run:\n",
    "        data_sim = hf.sim_signal(SNR=SNR,bvalues=bvalues,sims=sims,seed=seed)\n",
    "        # Only for visualisation purposes: here we create our \"Artifact\" in wandb --> this allows viewing the data in your wandb account\n",
    "        for i in range(4):\n",
    "            #make b-value data pairs\n",
    "            example_data=[[x,y] for (x,y) in zip(bvalues,data_sim[0][i])]\n",
    "            # put it in a table\n",
    "            table = wandb.Table(data=example_data, columns=[\"b-values\", \"signal\"])\n",
    "            #tell wandb to plot the table\n",
    "            wandb.log({\"data_plot \" + str(i): wandb.plot.scatter(table, \"b-values\", \"signal\")})\n",
    "\n",
    "        # here we split the data into train (70%), test (15%) and validation (15%) sets\n",
    "        #split = int(np.floor(len(data_sim[0]) * 0.7))\n",
    "        train_set, test_set, val_set = torch.utils.data.random_split([[data_sim[0][i,:],data_sim[1][i],data_sim[2][i],data_sim[3][i]] for i in range(len(data_sim[3]))],[0.7,0.15,0.15])\n",
    "        #split = int(np.floor(len(rest) * 0.5))\n",
    "        #test_set, val_set = torch.utils.data.random_split([[rest[0][i,:],rest[1][i],rest[2][i],rest[3][i]] for i in range(len(rest[3]))],[split, len(rest[0]) - split])\n",
    "\n",
    "        # train loader loads the trianing data. We want to shuffle to make sure data order is modified each epoch and different data is selected each epoch.\n",
    "        trainloader = torch.utils.data.DataLoader(train_set,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       drop_last=True)\n",
    "        # validation data is loaded here. By not shuffling, we make sure the same data is loaded for validation every time. We can use substantially more data per batch as we are not training.\n",
    "        inferloader = torch.utils.data.DataLoader(val_set,\n",
    "                                       batch_size=min(batch_size,len(val_set)),\n",
    "                                       shuffle=False,\n",
    "                                       drop_last=False)\n",
    "            # validation data is loaded here. By not shuffling, we make sure the same data is loaded for validation every time. We can use substantially more data per batch as we are not training.\n",
    "        testloader = torch.utils.data.DataLoader(test_set,\n",
    "                                       batch_size=min(batch_size,len(test_set)),\n",
    "                                       shuffle=False,\n",
    "                                       drop_last=False)\n",
    "    return trainloader, inferloader, testloader\n",
    "sim_dat(bvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Design a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# funtion for stacking the layers and making the model\n",
    "def make_model(n_inputs=5,n_hidden=1,n_outputs=1):\n",
    "    #initialize the model object\n",
    "    model = nn.Sequential()\n",
    "    # fill out the model with hidden layers.\n",
    "    for i in range(n_hidden):\n",
    "        # as we loop, we add hidden layers\n",
    "        model.add_module('layer_linear'+str(i), nn.Linear(n_inputs, n_inputs))\n",
    "        # we also add a ReLu layer\n",
    "        model.add_module('layer_ReLu'+str(i), nn.ReLU())\n",
    "    #and a final output layer\n",
    "    model.add_module('last_layer',nn.Linear(n_inputs, n_outputs))\n",
    "    # to ensure positive predictions, we end with a ReLu function before giving output\n",
    "    model.add_module('last',nn.Sigmoid())\n",
    "    model.apply(init_weights)\n",
    "    return model\n",
    "\n",
    "# function for initializing network weights for individual layers\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "train your first network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_network(name, epochs=200, learningrate=0.1, hidden_layers=2, seed=42, optimizer='SGD',bvalues=bvalues,batch_size=16,sims=1000):\n",
    "\n",
    "    trainloader, inferloader, testloader = sim_dat(bvalues,batch_size=batch_size,sims=sims)\n",
    "\n",
    "    model = make_model(n_inputs=len(bvalues), n_hidden=hidden_layers, n_outputs=1)\n",
    "\n",
    "    # initialize model --> we did this above, but during the exercise, you might be re-running this part of the script several times with different settings. This way we make sure you re-initiate the training and don't continue in the last model\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # initialize wandb\n",
    "    wandb.init(\n",
    "            project=\"AI_for_medical_imaging\", job_type=\"training\", name=name)\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # probe available devices\n",
    "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.determinstic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set default device. If GPU is available, the network will be trained on the GPU. Note that further down in the code, stuff will be sent \".to(device)\" to make sure it is available on the GPU.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    # define the loss of the network (mean square error)\n",
    "    loss_module = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "    # the optimizer determines how strongly to update the network's weights based on the calculated loss.\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learningrate)\n",
    "    else:\n",
    "        raise NotImplementedError('this optimizer is not implemented yet...')\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # initiate losses to 0\n",
    "        train_loss_f = 0\n",
    "        val_loss_f = 0\n",
    "        # set model to training such that forward passes are remembered (requiered for backpropogating the loss)\n",
    "        model.train()\n",
    "        #loop over all training data0\n",
    "        SD_train = 0\n",
    "        sys_train = 0\n",
    "        for x in trainloader:\n",
    "            # reset the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # get data (x[0]) and put the data on the GPU if available\n",
    "            batch=x[0].to(device)\n",
    "            # get the reference f (x[2]) --> note x[1] and x[3] are D and Dp respectively\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            # put the data through the neural network\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            # calculate loss (compare predicted f to the ground trueth)\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            #add found loss to the train loss, to keep track of the loss this epoch\n",
    "            train_loss_f += loss_f.item()\n",
    "            # propogate the loss through the network (calculate d_wights/d_loss)\n",
    "            loss_f.backward()\n",
    "            # update all weights accoording to their derrivatives to the loss.\n",
    "            optimizer.step()\n",
    "            # calculate the standard deviation and systematic error on the trianing data\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(),f_ref.cpu().detach().numpy())\n",
    "            # add the errors to ultimately calculate their mean over the trianing data. calculating mean SDs goes via the Root Mean Squares. So add SDs squared\n",
    "            SD_train += SD**2\n",
    "            sys_train += sys\n",
    "        # now divide by the total amount of training data to calculate the mean (sys error) and square of mean (SD).\n",
    "        SD_train = np.sqrt(SD_train/trainloader.__len__())\n",
    "        sys_train = sys_train/trainloader.__len__()\n",
    "        # after training, set model to evaluation mode\n",
    "        model.eval()\n",
    "        # initialize error_metrics\n",
    "        SD_val=0\n",
    "        sys_val=0\n",
    "        ######################your code here for validation loss#########################\n",
    "        #make b-value data pairs: Note these currently contain the f_ref and f_pred from the trianing data. You may want to swap to validation data once implemented\n",
    "        example_data=[[x,y] for (x,y) in zip(f_ref.cpu().detach().numpy(),f_pred.cpu().detach().numpy())]\n",
    "        # put it in a table\n",
    "        table = wandb.Table(data=example_data, columns=[\"f_ref\", \"f_pred\"])\n",
    "        #tell wandb to plot the table\n",
    "        # note that some parameters are being logged which you still need to define in the validation loop!\n",
    "        if epoch % 10 == 0:\n",
    "            wandb.log({\"loss/train\": train_loss_f/trainloader.__len__(),\"loss/val\": val_loss_f/inferloader.__len__(),\"error/random error\":SD_train,\"error/systematic error\":sys_train,\"data_plot epoch \" + str(epoch): wandb.plot.scatter(table, \"f_ref\", \"f_pred\", title=f'epoch{epoch}')})\n",
    "\n",
    "        ## print output in terminal. Only useful for debugging when WandB does not work\n",
    "        #print('epoch = ' + str(epoch) + ' train loss =' + str(train_loss_f/trainloader.__len__()) +' val loss =' + str(val_loss_f/inferloader.__len__()) + 'the systematic error is ' + str(sys_val) + ' and the random error is ' + str(SD_val))\n",
    "    wandb.finish()\n",
    "    #return val_test SD_test\n",
    "\n",
    "train_network('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# First week (on schedule means finish by Friday) [if updated: 7-2-2025]\n",
    "For these exercises, you will want to produce new cells that generate the outputs. The notebook cells should run and produce the figures without input of the examiners.\n",
    "\n",
    "## 1A-C: train the neural network\n",
    "Adapt the script above for your exercises A-C such that it produces the desired results and plots. Describe the results/intepertation in this text baloon.\n",
    "\n",
    "A.\tThe current network implementation only looks at training data. This means that the network’s performance is over-estimated. Please use the validation set to monitor performance during training (note that we have already put the model on evaluation mode in line 59). At what point is the network fully trained? Explain how you know this. Show the effect from overfitting and underfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Answer: The network is fully trained when the validation loss stops decreasing and when it starts to increase, it is a sign of overfitting. Underfitting is when the validation loss is still decreasing as well as the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_network(name, epochs=200, learningrate=0.1, hidden_layers=2, seed=42, optimizer='SGD',bvalues=bvalues,batch_size=16,sims=1000):\n",
    "\n",
    "    trainloader, inferloader, testloader = sim_dat(bvalues,batch_size=batch_size,sims=sims)\n",
    "\n",
    "    model = make_model(n_inputs=len(bvalues), n_hidden=hidden_layers, n_outputs=1)\n",
    "\n",
    "    # initialize model --> we did this above, but during the exercise, you might be re-running this part of the script several times with different settings. This way we make sure you re-initiate the training and don't continue in the last model\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # initialize wandb\n",
    "    wandb.init(\n",
    "            project=\"AI_for_medical_imaging\", job_type=\"training\", name=name)\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # probe available devices\n",
    "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set default device. If GPU is available, the network will be trained on the GPU. Note that further down in the code, stuff will be sent \".to(device)\" to make sure it is available on the GPU.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    # define the loss of the network (mean square error)\n",
    "    loss_module = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "    # the optimizer determines how strongly to update the network's weights based on the calculated loss.\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learningrate)\n",
    "    else:\n",
    "        raise NotImplementedError('this optimizer is not implemented yet...')\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # initiate losses to 0\n",
    "        train_loss_f = 0\n",
    "        val_loss_f = 0\n",
    "        # set model to training such that forward passes are remembered (requiered for backpropogating the loss)\n",
    "        model.train()\n",
    "        # loop over all training data\n",
    "        SD_train = 0\n",
    "        sys_train = 0\n",
    "        for x in trainloader:\n",
    "            # reset the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # get data (x[0]) and put the data on the GPU if available\n",
    "            batch=x[0].to(device)\n",
    "            # get the reference f (x[2]) --> note x[1] and x[3] are D and Dp respectively\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            # put the data through the neural network\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            # calculate loss (compare predicted f to the ground trueth)\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            #add found loss to the train loss, to keep track of the loss this epoch\n",
    "            train_loss_f += loss_f.item()\n",
    "            # propogate the loss through the network (calculate d_wights/d_loss)\n",
    "            loss_f.backward()\n",
    "            # update all weights accoording to their derrivatives to the loss.\n",
    "            optimizer.step()\n",
    "            # calculate the standard deviation and systematic error on the trianing data\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(),f_ref.cpu().detach().numpy())\n",
    "            # add the errors to ultimately calculate their mean over the trianing data. calculating mean SDs goes via the Root Mean Squares. So add SDs squared\n",
    "            SD_train += SD**2\n",
    "            sys_train += sys\n",
    "        # now divide by the total amount of training data to calculate the mean (sys error) and square of mean (SD).\n",
    "        SD_train = np.sqrt(SD_train/trainloader.__len__())\n",
    "        sys_train = sys_train/trainloader.__len__()\n",
    "\n",
    "        # model validation\n",
    "        model.eval()\n",
    "        SD_val = 0\n",
    "        sys_val = 0\n",
    "        for x in inferloader:\n",
    "            batch = x[0].to(device)\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            val_loss_f += loss_f.item()\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "            SD_val += SD**2\n",
    "            sys_val += sys\n",
    "        SD_val = np.sqrt(SD_val/inferloader.__len__())\n",
    "        sys_val = sys_val/inferloader.__len__()\n",
    "\n",
    "        # make b-value data pairs: Note these currently contain the f_ref and f_pred from the trianing data. You may want to swap to validation data once implemented\n",
    "        example_data = [[x, y] for (x, y) in zip(f_ref.cpu().detach().numpy(), f_pred.cpu().detach().numpy())]\n",
    "        # put it in a table\n",
    "        table = wandb.Table(data=example_data, columns=[\"f_ref\", \"f_pred\"])\n",
    "        # tell wandb to plot the table\n",
    "        if epoch % 10 == 0:\n",
    "            wandb.log({\"loss/train\": train_loss_f/trainloader.__len__(),\"loss/val\": val_loss_f/inferloader.__len__(),\"error/random error\":SD_train,\"error/systematic error\":sys_train,\"data_plot epoch \" + str(epoch): wandb.plot.scatter(table, \"f_ref\", \"f_pred\", title=f'epoch{epoch}')})\n",
    "        # print('epoch = ' + str(epoch) + ' train loss =' + str(train_loss_f/trainloader.__len__()) + ' val loss =' + str(val_loss_f/inferloader.__len__()) + ' the systematic error is ' + str(sys_val) + ' and the random error is ' + str(SD_val))\n",
    "    wandb.finish()\n",
    "    # return val_test SD_test\n",
    "\n",
    "train_network('test_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.\tSimilarly, use the test dataset to test for final performance. Explain why this is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 train loss =0.04513556835090005 val loss =0.03459770530462265 the systematic error is 0.00865134 and the random error is 0.18117906\n",
      "epoch = 1 train loss =0.03319112588326598 val loss =0.032460377737879756 the systematic error is 0.0174763 and the random error is 0.17479393\n",
      "epoch = 2 train loss =0.030503191357088642 val loss =0.02954259105026722 the systematic error is 0.004253471 and the random error is 0.16744\n",
      "epoch = 3 train loss =0.027607195729086566 val loss =0.02704747226089239 the systematic error is -0.007581259 and the random error is 0.16005728\n",
      "epoch = 4 train loss =0.025489814622804176 val loss =0.02457853825762868 the systematic error is -0.006479293 and the random error is 0.15260433\n",
      "epoch = 5 train loss =0.022801014204877755 val loss =0.02229931829497218 the systematic error is 0.009210886 and the random error is 0.1452167\n",
      "epoch = 6 train loss =0.020442737071493338 val loss =0.020200508739799262 the systematic error is 0.015510606 and the random error is 0.13767761\n",
      "epoch = 7 train loss =0.01799984044546998 val loss =0.017998893931508064 the systematic error is 0.006961043 and the random error is 0.1306119\n",
      "epoch = 8 train loss =0.016049255118813624 val loss =0.016643809713423253 the systematic error is 0.018443605 and the random error is 0.124549426\n",
      "epoch = 9 train loss =0.0146440249369588 val loss =0.015142165310680866 the systematic error is -0.007036153 and the random error is 0.11993044\n",
      "epoch = 10 train loss =0.013340270926439485 val loss =0.014101962372660638 the systematic error is -9.6676966e-05 and the random error is 0.11603695\n",
      "epoch = 11 train loss =0.012413521957865287 val loss =0.013386228447780013 the systematic error is 0.0033804835 and the random error is 0.11312053\n",
      "epoch = 12 train loss =0.011800009887232336 val loss =0.012866000644862652 the systematic error is 0.0027326809 and the random error is 0.111020714\n",
      "epoch = 13 train loss =0.011267007447692544 val loss =0.0126850132830441 the systematic error is -0.010873368 and the random error is 0.10982963\n",
      "epoch = 14 train loss =0.010817824278113454 val loss =0.012404736783355474 the systematic error is 0.014445158 and the random error is 0.108314365\n",
      "epoch = 15 train loss =0.01076830696141304 val loss =0.012225556513294577 the systematic error is -0.0118079595 and the random error is 0.10785948\n",
      "epoch = 16 train loss =0.010421446502901787 val loss =0.011920835124328732 the systematic error is 0.0096277315 and the random error is 0.10680326\n",
      "epoch = 17 train loss =0.010199499944614809 val loss =0.011718898033723234 the systematic error is 0.0010955641 and the random error is 0.10634243\n",
      "epoch = 18 train loss =0.010227748907582705 val loss =0.011608942225575448 the systematic error is 0.0038550608 and the random error is 0.10582813\n",
      "epoch = 19 train loss =0.010209756296907747 val loss =0.011590836057439446 the systematic error is -0.007890098 and the random error is 0.105542086\n",
      "epoch = 20 train loss =0.009950048095265101 val loss =0.01167642930522561 the systematic error is -0.014479421 and the random error is 0.10527266\n",
      "epoch = 21 train loss =0.00972670130431652 val loss =0.011370314983651042 the systematic error is 0.009275662 and the random error is 0.104489595\n",
      "epoch = 22 train loss =0.009717342194689567 val loss =0.011253774585202336 the systematic error is 0.007429472 and the random error is 0.10411028\n",
      "epoch = 23 train loss =0.009757757879966912 val loss =0.011134219029918313 the systematic error is 0.003306066 and the random error is 0.10377133\n",
      "epoch = 24 train loss =0.009723875455038493 val loss =0.01154112471267581 the systematic error is 0.022702519 and the random error is 0.10333909\n",
      "epoch = 25 train loss =0.009791154490220685 val loss =0.011039488133974373 the systematic error is 0.0090931645 and the random error is 0.1030305\n",
      "epoch = 26 train loss =0.009539913191178511 val loss =0.010905535449273885 the systematic error is 0.0033357632 and the random error is 0.10274368\n",
      "epoch = 27 train loss =0.009436429110030795 val loss =0.010832474729977549 the systematic error is -0.00042455102 and the random error is 0.102458596\n",
      "epoch = 28 train loss =0.009440633408768578 val loss =0.0107629110570997 the systematic error is -9.786524e-06 and the random error is 0.102146804\n",
      "epoch = 29 train loss =0.009234707380190145 val loss =0.010704876063391567 the systematic error is -0.0023966527 and the random error is 0.10185645\n",
      "epoch = 30 train loss =0.009367353001306223 val loss =0.010631401487626136 the systematic error is -0.0018370198 and the random error is 0.101530135\n",
      "epoch = 31 train loss =0.009149492490863385 val loss =0.010564682330004871 the systematic error is 0.0050364365 and the random error is 0.10112252\n",
      "epoch = 32 train loss =0.009103805249080409 val loss =0.010482692485675215 the systematic error is 0.000980923 and the random error is 0.10085561\n",
      "epoch = 33 train loss =0.009166244601527618 val loss =0.01057868991047144 the systematic error is 0.013944553 and the random error is 0.10040344\n",
      "epoch = 34 train loss =0.009043230772624875 val loss =0.010372612020000815 the systematic error is 0.00588124 and the random error is 0.10018758\n",
      "epoch = 35 train loss =0.008978280417491184 val loss =0.010390368360094725 the systematic error is -0.00765398 and the random error is 0.100159064\n",
      "epoch = 36 train loss =0.008792651985057218 val loss =0.010250282054767013 the systematic error is 0.0055413838 and the random error is 0.09963423\n",
      "epoch = 37 train loss =0.00890455071186257 val loss =0.010263830004259945 the systematic error is 0.0109593645 and the random error is 0.09926744\n",
      "epoch = 38 train loss =0.008927072317144551 val loss =0.010149630438536405 the systematic error is -0.0036581238 and the random error is 0.09924226\n",
      "epoch = 39 train loss =0.008831432923068141 val loss =0.01013235659338534 the systematic error is 0.009921139 and the random error is 0.09874898\n",
      "epoch = 40 train loss =0.00871105897673514 val loss =0.010034187184646725 the systematic error is -0.0028482478 and the random error is 0.09872462\n",
      "epoch = 41 train loss =0.008821995614832916 val loss =0.009963964764028787 the systematic error is -0.0005775266 and the random error is 0.098427534\n",
      "epoch = 42 train loss =0.008704560548933439 val loss =0.009941020607948303 the systematic error is -0.0038746602 and the random error is 0.09824815\n",
      "epoch = 43 train loss =0.008851613589497499 val loss =0.00986606574151665 the systematic error is 0.0054785493 and the random error is 0.09780623\n",
      "epoch = 44 train loss =0.008722567925402937 val loss =0.009994287509471178 the systematic error is 0.014850264 and the random error is 0.0975064\n",
      "epoch = 45 train loss =0.008629204429209579 val loss =0.010180516727268695 the systematic error is -0.01783578 and the random error is 0.097950354\n",
      "epoch = 46 train loss =0.008458799622996255 val loss =0.009795934543944895 the systematic error is -0.007044443 and the random error is 0.097389564\n",
      "epoch = 47 train loss =0.008503245135639296 val loss =0.009759800229221582 the systematic error is -0.00764698 and the random error is 0.09717085\n",
      "epoch = 48 train loss =0.00846974061650419 val loss =0.010001030308194459 the systematic error is -0.016881756 and the random error is 0.09724676\n",
      "epoch = 49 train loss =0.008489416487146776 val loss =0.009575940296053886 the systematic error is 0.0027628138 and the random error is 0.09652182\n",
      "epoch = 50 train loss =0.008524405071511865 val loss =0.009533856506459415 the systematic error is 0.001481808 and the random error is 0.09634446\n",
      "epoch = 51 train loss =0.008397651917496047 val loss =0.009502468723803758 the systematic error is -0.0010605505 and the random error is 0.09619712\n",
      "epoch = 52 train loss =0.008173629468263582 val loss =0.009454621048644186 the systematic error is 0.0030549555 and the random error is 0.095925085\n",
      "epoch = 53 train loss =0.008302267110191806 val loss =0.009465572307817638 the systematic error is -0.005169792 and the random error is 0.0958988\n",
      "epoch = 54 train loss =0.008323911252583182 val loss =0.009372987388633191 the systematic error is 0.0014072137 and the random error is 0.09555569\n",
      "epoch = 55 train loss =0.008318705614223036 val loss =0.009443488786928356 the systematic error is 0.01169713 and the random error is 0.09522211\n",
      "epoch = 56 train loss =0.008117485179587505 val loss =0.009303849563002587 the systematic error is 0.0042752703 and the random error is 0.09512856\n",
      "epoch = 57 train loss =0.00817224429378849 val loss =0.009661187278106808 the systematic error is 0.020850714 and the random error is 0.0948033\n",
      "epoch = 58 train loss =0.008156975460520317 val loss =0.00947493405546993 the systematic error is -0.013410384 and the random error is 0.09518711\n",
      "epoch = 59 train loss =0.008137360605043035 val loss =0.009206842072308064 the systematic error is 0.006184389 and the random error is 0.09454162\n",
      "epoch = 60 train loss =0.008045854712944738 val loss =0.009203941887244582 the systematic error is -0.005262158 and the random error is 0.09458947\n",
      "epoch = 61 train loss =0.007914702900750347 val loss =0.009186908742412925 the systematic error is -0.0063052527 and the random error is 0.0944499\n",
      "epoch = 62 train loss =0.008005667450772814 val loss =0.00944288456812501 the systematic error is 0.019860927 and the random error is 0.09391137\n",
      "epoch = 63 train loss =0.00799221459906115 val loss =0.009059858368709683 the systematic error is 0.004788612 and the random error is 0.09388462\n",
      "epoch = 64 train loss =0.007978044688528361 val loss =0.009021494584158064 the systematic error is 0.0036908325 and the random error is 0.0937365\n",
      "epoch = 65 train loss =0.007912208851383523 val loss =0.008988163620233535 the systematic error is 0.0025270693 and the random error is 0.093609676\n",
      "epoch = 66 train loss =0.00791645726340628 val loss =0.009657261869870126 the systematic error is 0.02701589 and the random error is 0.093276866\n",
      "epoch = 67 train loss =0.007905992419393949 val loss =0.009103350224904716 the systematic error is -0.010891015 and the random error is 0.09363489\n",
      "epoch = 68 train loss =0.007799596173775404 val loss =0.009096874250099063 the systematic error is 0.015177677 and the random error is 0.09299968\n",
      "epoch = 69 train loss =0.007819125114745178 val loss =0.0089619368663989 the systematic error is -0.007658555 and the random error is 0.09321794\n",
      "epoch = 70 train loss =0.007836883357011302 val loss =0.008841071918141097 the systematic error is 0.0012342551 and the random error is 0.09288208\n",
      "epoch = 71 train loss =0.007660008317162824 val loss =0.008906802209094167 the systematic error is -0.007638653 and the random error is 0.09293573\n",
      "epoch = 72 train loss =0.007757369932437012 val loss =0.008801234886050224 the systematic error is -0.0017727539 and the random error is 0.092671715\n",
      "epoch = 73 train loss =0.007761435117572546 val loss =0.008781107794493436 the systematic error is -0.0025773947 and the random error is 0.092552364\n",
      "epoch = 74 train loss =0.007817384906026513 val loss =0.009046075399965048 the systematic error is 0.018539142 and the random error is 0.09214226\n",
      "epoch = 75 train loss =0.007703403276283034 val loss =0.00875676611904055 the systematic error is 0.008152258 and the random error is 0.092107885\n",
      "epoch = 76 train loss =0.007530639917308161 val loss =0.008689577504992486 the systematic error is 0.003874141 and the random error is 0.09203623\n",
      "epoch = 77 train loss =0.0075903395461568305 val loss =0.008665999118238687 the systematic error is 0.0038552335 and the random error is 0.09191321\n",
      "epoch = 78 train loss =0.007451762407368352 val loss =0.008755470009054989 the systematic error is 0.012138636 and the random error is 0.091667846\n",
      "epoch = 79 train loss =0.00778630951982598 val loss =0.008615870622452348 the systematic error is 0.0027123163 and the random error is 0.091697864\n",
      "epoch = 80 train loss =0.00752690828643566 val loss =0.008600820926949382 the systematic error is 0.004744614 and the random error is 0.09153127\n",
      "epoch = 81 train loss =0.007587415112052546 val loss =0.00865937516791746 the systematic error is 0.010777735 and the random error is 0.091337055\n",
      "epoch = 82 train loss =0.00742533532794305 val loss =0.008599052601493896 the systematic error is 0.008443475 and the random error is 0.09124381\n",
      "epoch = 83 train loss =0.007371038656010357 val loss =0.008565672195982189 the systematic error is -0.0041317283 and the random error is 0.09138207\n",
      "epoch = 84 train loss =0.007582747464089892 val loss =0.008520018891431391 the systematic error is 0.0049446435 and the random error is 0.09108752\n",
      "epoch = 85 train loss =0.00763961101535621 val loss =0.00853714884724468 the systematic error is -0.0049301656 and the random error is 0.091196276\n",
      "epoch = 86 train loss =0.007610468399645977 val loss =0.008685627696104347 the systematic error is -0.012351864 and the random error is 0.09130946\n",
      "epoch = 87 train loss =0.0074925282320310906 val loss =0.008729447645600885 the systematic error is -0.014244182 and the random error is 0.09127831\n",
      "epoch = 88 train loss =0.007353926250754401 val loss =0.008544850605539977 the systematic error is -0.008406072 and the random error is 0.09099844\n",
      "epoch = 89 train loss =0.007535949565990027 val loss =0.008442557230591775 the systematic error is -0.0031445753 and the random error is 0.09076528\n",
      "epoch = 90 train loss =0.007338228045291332 val loss =0.008519000082742423 the systematic error is -0.008805377 and the random error is 0.090822235\n",
      "epoch = 91 train loss =0.007335323943258371 val loss =0.008446457143872977 the systematic error is -0.006057715 and the random error is 0.090643056\n",
      "epoch = 92 train loss =0.0072779551657393225 val loss =0.008362884796224535 the systematic error is 0.002408734 and the random error is 0.090341434\n",
      "epoch = 93 train loss =0.007261870185259816 val loss =0.008444931684061885 the systematic error is -0.007831736 and the random error is 0.09050371\n",
      "epoch = 94 train loss =0.0072134591768993886 val loss =0.008331740694120526 the systematic error is 0.0028124577 and the random error is 0.090172775\n",
      "epoch = 95 train loss =0.007201785779406511 val loss =0.00834671143675223 the systematic error is -0.0035417583 and the random error is 0.09024257\n",
      "epoch = 96 train loss =0.007286003048986543 val loss =0.008344489824958145 the systematic error is -0.004624593 and the random error is 0.0901829\n",
      "epoch = 97 train loss =0.007375591456197029 val loss =0.008423436316661537 the systematic error is -0.0094792135 and the random error is 0.09025287\n",
      "epoch = 98 train loss =0.007268004671692155 val loss =0.008910743379965424 the systematic error is 0.026204282 and the random error is 0.089571945\n",
      "epoch = 99 train loss =0.007355117433985999 val loss =0.008270954294130207 the systematic error is -0.0023703952 and the random error is 0.08984851\n",
      "epoch = 100 train loss =0.007078718450895056 val loss =0.008308431273326278 the systematic error is 0.010039765 and the random error is 0.08951889\n",
      "epoch = 101 train loss =0.007274862178493031 val loss =0.008222254319116473 the systematic error is 0.0020060234 and the random error is 0.089592725\n",
      "epoch = 102 train loss =0.00715533736010277 val loss =0.008219397382345051 the systematic error is -0.0012640433 and the random error is 0.089592956\n",
      "epoch = 103 train loss =0.007226789072372539 val loss =0.008200733526609837 the systematic error is -0.0001132749 and the random error is 0.08949416\n",
      "epoch = 104 train loss =0.007214778027129035 val loss =0.008195399236865342 the systematic error is -0.0019609756 and the random error is 0.089438595\n",
      "epoch = 105 train loss =0.007269369790243895 val loss =0.008380046323873102 the systematic error is -0.012217946 and the random error is 0.08966642\n",
      "epoch = 106 train loss =0.0070636182790622115 val loss =0.008247134741395712 the systematic error is 0.011123439 and the random error is 0.08903565\n",
      "epoch = 107 train loss =0.0070870126879145935 val loss =0.008669299050234258 the systematic error is 0.023833014 and the random error is 0.08889572\n",
      "epoch = 108 train loss =0.007096776993252164 val loss =0.008163296012207865 the systematic error is 0.006661157 and the random error is 0.08903608\n",
      "epoch = 109 train loss =0.007246367887832051 val loss =0.00824669199064374 the systematic error is -0.008706185 and the random error is 0.08934835\n",
      "epoch = 110 train loss =0.007176956427175292 val loss =0.008417473989538848 the systematic error is -0.014859507 and the random error is 0.089504994\n",
      "epoch = 111 train loss =0.007123977379050366 val loss =0.00810597171075642 the systematic error is 0.0016461253 and the random error is 0.08895787\n",
      "epoch = 112 train loss =0.007192878523668231 val loss =0.00826400425285101 the systematic error is -0.010678283 and the random error is 0.08922937\n",
      "epoch = 113 train loss =0.0071560078798684965 val loss =0.008088146476075054 the systematic error is 0.0011348901 and the random error is 0.08886514\n",
      "epoch = 114 train loss =0.00731665407697302 val loss =0.008138717571273445 the systematic error is 0.009069391 and the random error is 0.08868693\n",
      "epoch = 115 train loss =0.007038663796604026 val loss =0.008214317145757377 the systematic error is 0.013390024 and the random error is 0.088563055\n",
      "epoch = 116 train loss =0.007191190734332384 val loss =0.0081644898513332 the systematic error is 0.011755918 and the random error is 0.088505775\n",
      "epoch = 117 train loss =0.007139328585634398 val loss =0.008111543953418732 the systematic error is 0.009428738 and the random error is 0.08848981\n",
      "epoch = 118 train loss =0.00702808368517909 val loss =0.008157591114286333 the systematic error is -0.008482312 and the random error is 0.08886716\n",
      "epoch = 119 train loss =0.007006501616520244 val loss =0.008048676908947528 the systematic error is -0.001734424 and the random error is 0.0886392\n",
      "epoch = 120 train loss =0.006977961550271789 val loss =0.008062122762203217 the systematic error is 0.0074755056 and the random error is 0.08839644\n",
      "epoch = 121 train loss =0.0072127924853026175 val loss =0.008144524472299963 the systematic error is 0.012324813 and the random error is 0.08830765\n",
      "epoch = 122 train loss =0.007155136205255985 val loss =0.008018408075440676 the systematic error is 0.0012697806 and the random error is 0.08846561\n",
      "epoch = 123 train loss =0.007023854668490415 val loss =0.008108832186553627 the systematic error is -0.007719066 and the random error is 0.08866115\n",
      "epoch = 124 train loss =0.007101852354745186 val loss =0.008019802975468338 the systematic error is -0.0022118338 and the random error is 0.0884565\n",
      "epoch = 125 train loss =0.0072075182756105825 val loss =0.008025342435576021 the systematic error is -0.0032843598 and the random error is 0.08846106\n",
      "epoch = 126 train loss =0.006994678950218787 val loss =0.007992106210440397 the systematic error is -0.00011012247 and the random error is 0.088319845\n",
      "epoch = 127 train loss =0.007078358459524637 val loss =0.007981395092792809 the systematic error is 0.0008181046 and the random error is 0.08825595\n",
      "epoch = 128 train loss =0.00705528287704341 val loss =0.008153389522340149 the systematic error is -0.011124818 and the random error is 0.08854915\n",
      "epoch = 129 train loss =0.007027468971669847 val loss =0.007971515587996691 the systematic error is 0.0032871217 and the random error is 0.088143446\n",
      "epoch = 130 train loss =0.0070188928038141755 val loss =0.008368787541985511 the systematic error is 0.021022167 and the random error is 0.0879006\n",
      "epoch = 131 train loss =0.0069904375962133326 val loss =0.008029072359204293 the systematic error is 0.010104919 and the random error is 0.08794145\n",
      "epoch = 132 train loss =0.0070413552376246726 val loss =0.007978802372235805 the systematic error is 0.006989301 and the random error is 0.08796787\n",
      "epoch = 133 train loss =0.007049656873785479 val loss =0.008001729322131723 the systematic error is -0.0053027594 and the random error is 0.08822996\n",
      "epoch = 134 train loss =0.0069975012447685 val loss =0.007992500136606396 the systematic error is -0.005209453 and the random error is 0.088176675\n",
      "epoch = 135 train loss =0.007080346990246759 val loss =0.00803584004752338 the systematic error is 0.011381464 and the random error is 0.08782024\n",
      "epoch = 136 train loss =0.006940330026757925 val loss =0.00793602312915027 the systematic error is 0.003682175 and the random error is 0.08792048\n",
      "epoch = 137 train loss =0.006970892714466466 val loss =0.00794371822848916 the systematic error is 0.005871189 and the random error is 0.08783968\n",
      "epoch = 138 train loss =0.0070740881722507086 val loss =0.007961035659536719 the systematic error is -0.0043307524 and the random error is 0.08804267\n",
      "epoch = 139 train loss =0.007008292825979202 val loss =0.007945567835122347 the systematic error is 0.0068882694 and the random error is 0.087778635\n",
      "epoch = 140 train loss =0.007024847623502272 val loss =0.007915140176191927 the systematic error is 0.0030925584 and the random error is 0.08782481\n",
      "epoch = 141 train loss =0.007047609447739845 val loss =0.007914330251514912 the systematic error is -0.000841776 and the random error is 0.08787659\n",
      "epoch = 142 train loss =0.006959497219298122 val loss =0.007916879816912114 the systematic error is 0.005271703 and the random error is 0.087721206\n",
      "epoch = 143 train loss =0.006936783572052454 val loss =0.007942691631615161 the systematic error is 0.007913847 and the random error is 0.08765661\n",
      "epoch = 144 train loss =0.007094254424838826 val loss =0.008139158447738737 the systematic error is -0.0132976305 and the random error is 0.08815066\n",
      "epoch = 145 train loss =0.007021712599495469 val loss =0.008087933610659093 the systematic error is 0.0149486065 and the random error is 0.08754047\n",
      "epoch = 146 train loss =0.006942272069863975 val loss =0.007989949779585004 the systematic error is -0.007945543 and the random error is 0.08794055\n",
      "epoch = 147 train loss =0.007006035744060957 val loss =0.008673438522964715 the systematic error is 0.028272143 and the random error is 0.08755693\n",
      "epoch = 148 train loss =0.007028955895843548 val loss =0.008045568282250315 the systematic error is 0.013709326 and the random error is 0.08749752\n",
      "epoch = 149 train loss =0.007065606103170403 val loss =0.007884846837259828 the systematic error is 0.0030795932 and the random error is 0.08762806\n",
      "epoch = 150 train loss =0.006928016447873656 val loss =0.007964050583541393 the systematic error is 0.010298149 and the random error is 0.08750243\n",
      "epoch = 151 train loss =0.0069617663542631755 val loss =0.007900413183961064 the systematic error is 0.0062750923 and the random error is 0.087531984\n",
      "epoch = 152 train loss =0.007046742343105549 val loss =0.007967674499377608 the systematic error is 0.010836159 and the random error is 0.08745516\n",
      "epoch = 153 train loss =0.0070210642906902146 val loss =0.008072466065641493 the systematic error is 0.015033074 and the random error is 0.08741813\n",
      "epoch = 154 train loss =0.007044673160931399 val loss =0.007873665320221334 the systematic error is -0.0013521803 and the random error is 0.08760762\n",
      "epoch = 155 train loss =0.006929863737029738 val loss =0.008168047596700489 the systematic error is 0.01810405 and the random error is 0.08738095\n",
      "epoch = 156 train loss =0.0070554371869061576 val loss =0.007976458256598562 the systematic error is -0.008819494 and the random error is 0.0877724\n",
      "epoch = 157 train loss =0.007052653712805274 val loss =0.008388636028394103 the systematic error is -0.020641962 and the random error is 0.088141344\n",
      "epoch = 158 train loss =0.006853312004877384 val loss =0.00852091594133526 the systematic error is 0.026141394 and the random error is 0.08733758\n",
      "epoch = 159 train loss =0.006724077520545485 val loss =0.009382788930088282 the systematic error is 0.039148703 and the random error is 0.08738094\n",
      "epoch = 160 train loss =0.007006097552474848 val loss =0.00813663813751191 the systematic error is 0.017582485 and the random error is 0.08729598\n",
      "epoch = 161 train loss =0.006964109101614287 val loss =0.007892737188376487 the systematic error is -0.0054266816 and the random error is 0.08754971\n",
      "epoch = 162 train loss =0.00699824485169767 val loss =0.007838392595294863 the systematic error is 0.0017268559 and the random error is 0.08737299\n",
      "epoch = 163 train loss =0.006803003429478511 val loss =0.007851223775651306 the systematic error is -0.002532627 and the random error is 0.087432\n",
      "epoch = 164 train loss =0.006883627935420982 val loss =0.0078603008762002 the systematic error is -0.003728494 and the random error is 0.08744683\n",
      "epoch = 165 train loss =0.006971648341954448 val loss =0.007861982646863908 the systematic error is 0.006599948 and the random error is 0.08725895\n",
      "epoch = 166 train loss =0.006974559951421999 val loss =0.007949487201403826 the systematic error is 0.011752392 and the random error is 0.08721236\n",
      "epoch = 167 train loss =0.007061472758217607 val loss =0.00799443427240476 the systematic error is 0.01337854 and the random error is 0.087223366\n",
      "epoch = 168 train loss =0.006827637980973651 val loss =0.007956758816726505 the systematic error is 0.01180991 and the random error is 0.08723778\n",
      "epoch = 169 train loss =0.006869758419735834 val loss =0.008204617677256465 the systematic error is 0.01995716 and the random error is 0.08715848\n",
      "epoch = 170 train loss =0.0070265002039716 val loss =0.008443652815185488 the systematic error is -0.022555564 and the random error is 0.0879623\n",
      "epoch = 171 train loss =0.006970275729504782 val loss =0.007850584224797785 the systematic error is -0.0034782235 and the random error is 0.08737924\n",
      "epoch = 172 train loss =0.006924138171598315 val loss =0.007896264060400426 the systematic error is -0.0068846876 and the random error is 0.087439254\n",
      "epoch = 173 train loss =0.006992034170083528 val loss =0.007854873989708721 the systematic error is 0.005833734 and the random error is 0.0872556\n",
      "epoch = 174 train loss =0.006883934421768022 val loss =0.00786084842402488 the systematic error is -0.0046377787 and the random error is 0.087380104\n",
      "epoch = 175 train loss =0.00696878744354255 val loss =0.007851227233186365 the systematic error is -0.003951178 and the random error is 0.08735301\n",
      "epoch = 176 train loss =0.0068666065425806964 val loss =0.008022292074747384 the systematic error is 0.014789542 and the random error is 0.08714107\n",
      "epoch = 177 train loss =0.00684034654892288 val loss =0.007978179666679353 the systematic error is -0.010916463 and the random error is 0.08749726\n",
      "epoch = 178 train loss =0.00689919707690214 val loss =0.007828033436089754 the systematic error is 0.003103758 and the random error is 0.08723875\n",
      "epoch = 179 train loss =0.006827376717918141 val loss =0.007900346349924803 the systematic error is -0.0078002415 and the random error is 0.08737355\n",
      "epoch = 180 train loss =0.006921427397512246 val loss =0.007873375876806676 the systematic error is -0.006148746 and the random error is 0.08734337\n",
      "epoch = 181 train loss =0.006689520336167757 val loss =0.007908900885377079 the systematic error is -0.008307345 and the random error is 0.08736916\n",
      "epoch = 182 train loss =0.006687233516903117 val loss =0.007813335000537335 the systematic error is 0.0024108833 and the random error is 0.08717253\n",
      "epoch = 183 train loss =0.006790298638258909 val loss =0.008037479815538973 the systematic error is -0.0134965535 and the random error is 0.08745994\n",
      "epoch = 184 train loss =0.006941071202502001 val loss =0.007819598447531462 the systematic error is 0.0050944393 and the random error is 0.08708467\n",
      "epoch = 185 train loss =0.006783562349588718 val loss =0.007821527775377035 the systematic error is -0.0026868638 and the random error is 0.0872039\n",
      "epoch = 186 train loss =0.006927278862053225 val loss =0.007915629353374243 the systematic error is -0.008952865 and the random error is 0.08733216\n",
      "epoch = 187 train loss =0.006862202041977366 val loss =0.007824828359298408 the systematic error is -0.0038048085 and the random error is 0.08718573\n",
      "epoch = 188 train loss =0.006761463380656963 val loss =0.007880189782008528 the systematic error is 0.010459221 and the random error is 0.08694763\n",
      "epoch = 189 train loss =0.006887168840093668 val loss =0.008062717178836465 the systematic error is -0.014333598 and the random error is 0.08746078\n",
      "epoch = 190 train loss =0.0068946884360251036 val loss =0.007938149210531265 the systematic error is 0.013043751 and the random error is 0.08692586\n",
      "epoch = 191 train loss =0.0068051043064008615 val loss =0.007836992130614817 the systematic error is 0.007907921 and the random error is 0.08696566\n",
      "epoch = 192 train loss =0.006730546698320744 val loss =0.007817648001946509 the systematic error is -0.0038029752 and the random error is 0.08712992\n",
      "epoch = 193 train loss =0.006812049384597082 val loss =0.007907824660651385 the systematic error is -0.009266495 and the random error is 0.08724486\n",
      "epoch = 194 train loss =0.006705530058202702 val loss =0.007784877484664321 the systematic error is 0.002031779 and the random error is 0.08700268\n",
      "epoch = 195 train loss =0.006743814812453334 val loss =0.007808228861540556 the systematic error is 0.006101899 and the random error is 0.08694476\n",
      "epoch = 196 train loss =0.0068287765065771205 val loss =0.007858241570647805 the systematic error is -0.006768883 and the random error is 0.087189496\n",
      "epoch = 197 train loss =0.006854785140603781 val loss =0.007944911892991513 the systematic error is 0.013586104 and the random error is 0.08688318\n",
      "epoch = 198 train loss =0.006824257648225094 val loss =0.00800115237943828 the systematic error is 0.015579718 and the random error is 0.086872146\n",
      "epoch = 199 train loss =0.006809114451455169 val loss =0.00788198048248887 the systematic error is 0.010921776 and the random error is 0.086894974\n",
      "Test loss = 0.00849284476134926 Systematic error = 0.01655933 Random error = 0.089063354\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_network(name, epochs=200, learningrate=0.1, hidden_layers=2, seed=42, optimizer='SGD', bvalues=bvalues, batch_size=16, sims=1000):\n",
    "\n",
    "    trainloader, inferloader, testloader = sim_dat(bvalues, batch_size=batch_size, sims=sims)\n",
    "\n",
    "    model = make_model(n_inputs=len(bvalues), n_hidden=hidden_layers, n_outputs=1)\n",
    "\n",
    "    # initialize model --> we did this above, but during the exercise, you might be re-running this part of the script several times with different settings. This way we make sure you re-initiate the training and don't continue in the last model\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # initialize wandb\n",
    "    wandb.init(\n",
    "            project=\"AI_for_medical_imaging\", job_type=\"training\", name=name)\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # probe available devices\n",
    "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set default device. If GPU is available, the network will be trained on the GPU. Note that further down in the code, stuff will be sent \".to(device)\" to make sure it is available on the GPU.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    # define the loss of the network (mean square error)\n",
    "    loss_module = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "    # the optimizer determines how strongly to update the network's weights based on the calculated loss.\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learningrate)\n",
    "    else:\n",
    "        raise NotImplementedError('this optimizer is not implemented yet...')\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # initiate losses to 0\n",
    "        train_loss_f = 0\n",
    "        val_loss_f = 0\n",
    "        # set model to training such that forward passes are remembered (requiered for backpropogating the loss)\n",
    "        model.train()\n",
    "        # loop over all training data\n",
    "        SD_train = 0\n",
    "        sys_train = 0\n",
    "        for x in trainloader:\n",
    "            # reset the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # get data (x[0]) and put the data on the GPU if available\n",
    "            batch = x[0].to(device)\n",
    "            # get the reference f (x[2]) --> note x[1] and x[3] are D and Dp respectively\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            # put the data through the neural network\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            # calculate loss (compare predicted f to the ground trueth)\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            # add found loss to the train loss, to keep track of the loss this epoch\n",
    "            train_loss_f += loss_f.item()\n",
    "            # propogate the loss through the network (calculate d_wights/d_loss)\n",
    "            loss_f.backward()\n",
    "            # update all weights accoording to their derrivatives to the loss.\n",
    "            optimizer.step()\n",
    "            # calculate the standard deviation and systematic error on the trianing data\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "            # add the errors to ultimately calculate their mean over the trianing data. calculating mean SDs goes via the Root Mean Squares. So add SDs squared\n",
    "            SD_train += SD**2\n",
    "            sys_train += sys\n",
    "        # now divide by the total amount of training data to calculate the mean (sys error) and square of mean (SD).\n",
    "        SD_train = np.sqrt(SD_train/trainloader.__len__())\n",
    "        sys_train = sys_train/trainloader.__len__()\n",
    "\n",
    "        # model validation\n",
    "        model.eval()\n",
    "        SD_val = 0\n",
    "        sys_val = 0\n",
    "        for x in inferloader:\n",
    "            batch = x[0].to(device)\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            val_loss_f += loss_f.item()\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "            SD_val += SD**2\n",
    "            sys_val += sys\n",
    "        SD_val = np.sqrt(SD_val/inferloader.__len__())\n",
    "        sys_val = sys_val/inferloader.__len__()\n",
    "\n",
    "        # make b-value data pairs: Note these currently contain the f_ref and f_pred from the trianing data. You may want to swap to validation data once implemented\n",
    "        example_data = [[x, y] for (x, y) in zip(f_ref.cpu().detach().numpy(), f_pred.cpu().detach().numpy())]\n",
    "        # put it in a table\n",
    "        table = wandb.Table(data=example_data, columns=[\"f_ref\", \"f_pred\"])\n",
    "        # tell wandb to plot the table\n",
    "        if epoch % 10 == 0:\n",
    "            wandb.log({\"loss/train\": train_loss_f/trainloader.__len__(), \"loss/val\": val_loss_f/inferloader.__len__(), \"error/random error\": SD_train, \"error/systematic error\": sys_train, \"data_plot epoch \" + str(epoch): wandb.plot.scatter(table, \"f_ref\", \"f_pred\", title=f'epoch{epoch}')})\n",
    "\n",
    "        # print output in terminal. Only useful for debugging when WandB does not work\n",
    "        print('epoch = ' + str(epoch) + ' train loss =' + str(train_loss_f/trainloader.__len__()) + ' val loss =' + str(val_loss_f/inferloader.__len__()) + ' the systematic error is ' + str(sys_val) + ' and the random error is ' + str(SD_val))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    SD_test = 0\n",
    "    sys_test = 0\n",
    "    test_loss_f = 0\n",
    "    for x in testloader:\n",
    "        batch = x[0].to(device)\n",
    "        f_ref = torch.flatten(x[2].to(device))\n",
    "        f_pred = torch.flatten(model.forward(batch))\n",
    "        loss_f = loss_module(f_pred, f_ref)\n",
    "        test_loss_f += loss_f.item()\n",
    "        SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "        SD_test += SD**2\n",
    "        sys_test += sys\n",
    "    SD_test = np.sqrt(SD_test/testloader.__len__())\n",
    "    sys_test = sys_test/testloader.__len__()\n",
    "    # log test results to wandb\n",
    "    wandb.log({\"loss/test\": test_loss_f/testloader.__len__(), \"error/random error\": SD_test, \"error/systematic error\": sys_test})\n",
    "    # print('Test loss =', test_loss_f/testloader.__len__(), 'Systematic error =', sys_test, 'Random error =', SD_test)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "train_network('test_val_eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C.\tCurrently, standard gradient descent optimizer is being used to train the network, with a learning rate of 0.01. Investigate the performance of the network for different  optimizer (i.e. adam loss was discussed in the lecture) and explain what you see. What does the Adam  optimizer do differently from the SGD  optimizer that would make it perform better/differently?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer: Adam optimizer adapt the learning rate, so it converge faster than SGD, but it tends to overfit on the trainning data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 0.006711244955658913 Systematic error = -0.003411103 Random error = 0.080663174\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_network(name, epochs=200, learningrate=0.01, hidden_layers=2, seed=42, optimizer='SGD', bvalues=bvalues, batch_size=16, sims=1000):\n",
    "\n",
    "    trainloader, inferloader, testloader = sim_dat(bvalues, batch_size=batch_size, sims=sims)\n",
    "\n",
    "    model = make_model(n_inputs=len(bvalues), n_hidden=hidden_layers, n_outputs=1)\n",
    "\n",
    "    # initialize model --> we did this above, but during the exercise, you might be re-running this part of the script several times with different settings. This way we make sure you re-initiate the training and don't continue in the last model\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # initialize wandb\n",
    "    wandb.init(\n",
    "            project=\"AI_for_medical_imaging\", job_type=\"training\", name=name)\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # probe available devices\n",
    "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set default device. If GPU is available, the network will be trained on the GPU. Note that further down in the code, stuff will be sent \".to(device)\" to make sure it is available on the GPU.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    # define the loss of the network (mean square error)\n",
    "    loss_module = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "    # the optimizer determines how strongly to update the network's weights based on the calculated loss.\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learningrate)\n",
    "    elif optimizer == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learningrate)\n",
    "    else:\n",
    "        raise NotImplementedError('this optimizer is not implemented yet...')\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # initiate losses to 0\n",
    "        train_loss_f = 0\n",
    "        val_loss_f = 0\n",
    "        # set model to training such that forward passes are remembered (requiered for backpropogating the loss)\n",
    "        model.train()\n",
    "        # loop over all training data\n",
    "        SD_train = 0\n",
    "        sys_train = 0\n",
    "        for x in trainloader:\n",
    "            # reset the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # get data (x[0]) and put the data on the GPU if available\n",
    "            batch = x[0].to(device)\n",
    "            # get the reference f (x[2]) --> note x[1] and x[3] are D and Dp respectively\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            # put the data through the neural network\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            # calculate loss (compare predicted f to the ground trueth)\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            # add found loss to the train loss, to keep track of the loss this epoch\n",
    "            train_loss_f += loss_f.item()\n",
    "            # propogate the loss through the network (calculate d_wights/d_loss)\n",
    "            loss_f.backward()\n",
    "            # update all weights accoording to their derrivatives to the loss.\n",
    "            optimizer.step()\n",
    "            # calculate the standard deviation and systematic error on the trianing data\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "            # add the errors to ultimately calculate their mean over the trianing data. calculating mean SDs goes via the Root Mean Squares. So add SDs squared\n",
    "            SD_train += SD**2\n",
    "            sys_train += sys\n",
    "        # now divide by the total amount of training data to calculate the mean (sys error) and square of mean (SD).\n",
    "        SD_train = np.sqrt(SD_train/trainloader.__len__())\n",
    "        sys_train = sys_train/trainloader.__len__()\n",
    "\n",
    "        # model validation\n",
    "        model.eval()\n",
    "        SD_val = 0\n",
    "        sys_val = 0\n",
    "        for x in inferloader:\n",
    "            batch = x[0].to(device)\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            val_loss_f += loss_f.item()\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "            SD_val += SD**2\n",
    "            sys_val += sys\n",
    "        SD_val = np.sqrt(SD_val/inferloader.__len__())\n",
    "        sys_val = sys_val/inferloader.__len__()\n",
    "\n",
    "        # make b-value data pairs: Note these currently contain the f_ref and f_pred from the trianing data. You may want to swap to validation data once implemented\n",
    "        example_data = [[x, y] for (x, y) in zip(f_ref.cpu().detach().numpy(), f_pred.cpu().detach().numpy())]\n",
    "        # put it in a table\n",
    "        table = wandb.Table(data=example_data, columns=[\"f_ref\", \"f_pred\"])\n",
    "        # tell wandb to plot the table\n",
    "        if epoch % 10 == 0:\n",
    "            wandb.log({\"loss/train\": train_loss_f/trainloader.__len__(), \"loss/val\": val_loss_f/inferloader.__len__(), \"error/random error\": SD_train, \"error/systematic error\": sys_train, \"data_plot epoch \" + str(epoch): wandb.plot.scatter(table, \"f_ref\", \"f_pred\", title=f'epoch{epoch}')})\n",
    "\n",
    "        # print output in terminal. Only useful for debugging when WandB does not work\n",
    "        # print('epoch = ' + str(epoch) + ' train loss =' + str(train_loss_f/trainloader.__len__()) + ' val loss =' + str(val_loss_f/inferloader.__len__()) + ' the systematic error is ' + str(sys_val) + ' and the random error is ' + str(SD_val))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    SD_test = 0\n",
    "    sys_test = 0\n",
    "    test_loss_f = 0\n",
    "    for x in testloader:\n",
    "        batch = x[0].to(device)\n",
    "        f_ref = torch.flatten(x[2].to(device))\n",
    "        f_pred = torch.flatten(model.forward(batch))\n",
    "        loss_f = loss_module(f_pred, f_ref)\n",
    "        test_loss_f += loss_f.item()\n",
    "        SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "        SD_test += SD**2\n",
    "        sys_test += sys\n",
    "    SD_test = np.sqrt(SD_test/testloader.__len__())\n",
    "    sys_test = sys_test/testloader.__len__()\n",
    "\n",
    "    # log test results to wandb\n",
    "    wandb.log({\"loss/test\": test_loss_f/testloader.__len__(), \"error/random error test\": SD_test, \"error/systematic error test\": sys_test})\n",
    "    print('Test loss =', test_loss_f/testloader.__len__(), 'Systematic error =', sys_test, 'Random error =', SD_test)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "train_network('test_Adam_val_eval', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "D.\tReturn back to SGD. Test how the performance depends on the learning rate. This can be done by plotting the systematic (sys_test) and random (SD_test) errors as function of learning rate (10<LR<0.0000001; steps in order of magnitude; e.g. 10, 1, 0.1, ….).\n",
    "##### Plot the performance (sys_val and SD_val) as function of the learning rate and add this to your report. Explain what you see (hint: take a look at the loss curves).\n",
    "* Answer: Too high learning rate will cause the model converge unstably to overfit or even diverge, too low learning rate will cause the model to converge too slow and underfit. The optimal learning rate is around 0.01 to 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAHbCAYAAACp9SkGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAnLNJREFUeJzt3QV4U1cbB/B/HVpa3H24u7sPhvtw/9DBYIyx4T4YMhjDhsOA4WPD3d0ZNiju2kJL9X7PeyBZWtpSzW2S/+95ztPk5iZ5c3OT3jfnnPfaAdBAREREREREZmNvvqciIiIiIiIiwUSMiIiIiIjIzJiIERERERERmRkTMSIiIiIiIjNjIkZERERERGRmTMSIiIiIiIjMjIkYERERERGRmTERIyIiIiIiMjMmYkRERERERGbGRIyILMbChQvh6ekJS5I5c2Zomob27dvDEg0fPlzFT6QH+dzI/iefo/jsm2++wY0bNxAYGIgzZ87A2lj69xhRfMVEjEgH+fPnx+rVq3Hr1i34+vri3r172L59O3r37h0nz5cnTx51QB3fD2ZE2rRpVayFChWCLalUqZI60DE0OaB7/Pix2k9y586td3jxdjuFbi1atNA7xHj9Q0Z4261WrVq6xjZ48GA0aNAAlqhGjRqYNGkSDh06hI4dO+L777+P8D3w9vY2a3yWLq6+Gy15nyPr4ah3AES2pkyZMtizZw/u3LmDefPm4dGjR8iYMSNKly6Nvn374pdffon158ybNy9GjBiBvXv34vbt24jP0qVLp2KVJPXcuXMhbuvatSvs7a3796Off/4ZJ06cgJOTEwoWLIju3bujcuXKKnmXgw8KuZ1CO3LkiC7xWIp3796hS5cuHy0P/VkzN0le1qxZg40bN4ZYvnTpUqxcuRJ+fn6Ir6pWrYqgoCB07twZAQEBsEbyfyNBggS6vr7Y/m4Mb58jMicmYkRm9sMPP+D169coUaKE+msqZcqUusVlCeSXUGt34MABrF271nj96tWrmD17Ntq1a6d+daewt1Nk2NnZwdnZOcyDeldXV/j4+MQopoQJE6oe7vj+GVq+fDksRXBwcLxOwkSqVKnU+25JSVh09ne93wd+N5I1su6flonioWzZsuHSpUsfJWHi6dOnxsvSe3X27NkwH+PKlSvYunWr8boMxzp58iS8vLzU454/fx5fffWVuk3G9MuvfobHNAzvkOEeBp9//jn279+PN2/eqMf466+/VC9aWENqpPdu06ZN6rIMqezZs6e6XX6V3LVrl3oM6c368ssvQ9w/adKk6p+lxCb3lTg3b96sftk0kJjkdYhFixYZYzXMSwhrjpgcXMtrlceVg6EnT55gy5YtKFasWITvQ/ny5fHHH3+oX3qll0B6KKdMmaJ+9Q3rdUtP3fr169VleQ55LaF75xInTqzWf/XqFV6+fKleQ5IkSRDTgw/DfmNqwIABaijUs2fP1AGVbLcmTZp8dH/ZfjNmzFBDcC5cuKBe68WLF8McilauXDkcP35cbcd///0X3bp1CzMmBwcHDBkyRK0jjyfvydixY1WSY0qWy74i76v8ki1xyvtk2PcaNWpkfN8k/sKFC8doW4X32lu1aqVesxxIyr5umHdUsWJFzJw5U/2aLvuyQY8ePdT68tru37+veqnlvTUlvdqyPYsWLYp9+/bh7du3GDdunLpN9j35fMrnWV7zzZs3MX/+/E/GW79+ffXZk+eU55btK9s59H6WPXt29Zl++PCh2nZ3797FihUr4OHhEStDwEy/G8KbHxSVz8WnPqPy2IkSJUKHDh2Mn3l5/IjmiEXlPZKh2bt371bvkbzPAwcOjNT2iMx+LrF16tRJxR/6+yomSpYsqbaRfJdI3PLdXbZs2RDrZMqUSe2/8v9A9jP5LpDvtNDbKqL9PbLbKKb7QLJkybBkyRL1vW/4bpTv/phsr5h8N0a0zwl5TfKZlRErhu9MGXZKFNvYI0ZkZnLgL8MT8+XLpxKy8MiQnN9+++2j9YoXL45cuXJhzJgx6nr16tXV0J2dO3di0KBBapn8U5WD6unTp6sES4Z0yLBHOYi4fPmyWsfwt02bNli8eDG2bdum7i+/lMpBzsGDB1GkSJEQQxnlwEQODuQxv/32W7Ru3Vr9Y5d/3vLY8kv7unXr1JAR+acrw8QkKROfffYZGjZsqMb1ywFN6tSp8b///U8dxErSJweVEtPQoUMxevRozJkzx/iP9vDhw+FuJ/lnKf8gJamT7eXo6IgKFSqooZ6nTp0K937NmjVTr3XWrFl4/vy5OvDp06cPMmTIgObNm4dYV163bJ9jx46pSfmyzQ2T8+UXWQMZ4iIJniyT1yKJhmzbmMiSJYv6KwcvpuT9/PPPP9U2lwPDli1bqoPzL774Qm0LUxJT48aN8euvv6qDJTkoll+W5UDuxYsXxkRa5ilK8iBDQ2U7jhw5MswhP7Kd5QBG3svJkyejVKlSapiP7HfyPKGTht9//129n8uWLVPbTZIz2UckcZGYDPM15CBS9u3IFAdxd3dH8uTJP1ou72XoYWPyfsqBuhyYyf5oSPjkueX1jho1Cm5ubmqZzE+U179jxw61b0g88nmQHmz5TJn2ysrzy+dBPn/y2mRbSa+2YTtOmDBBHUjLexh6u4RFtqn8kCE/CMhfiV0+C5JgyedNyLAs2RddXFxUkikHiunTp0fdunVV0i8/pHxK6O0mPTmRuV9okf1cfOozKt9Bslx+BJg7d666jzxGeKLyHskPQJIUy/eS7F9NmzbFxIkTVfJh+mNWWCKzn0vs8oOFfH8YhnxG9H0VGVWqVFH7lWwb+QxKr6BsP0mUZLsZhuTK65XkTPY/SZ5kP5PtIEmbfKeG7p0Na3+P6TaKzD4gibh85mUbyfsliaP8MKTnd2NE+5z0cB49elR9D8n3hmyz2rVrY8GCBeqzKP9PiWKT/MdjY2MzU6tevboWEBCg2qFDh7QJEyZoNWrU0BwdHUOs5+Hhofn4+Gjjx48PsXzatGmat7e35urqqq5PnTpVe/XqlWZvbx/uczZp0kQTlSpVCrHczc1Ne/HihTZnzpwQy1OlSqW9fPkyxPKFCxeqx/juu++MyxInTqy9fftWCwoK0po3b25cnjNnTrXu8OHDjcucnZ01Ozu7EM+TOXNmzdfXVxsyZIhxWbFixdR927dv/9HrkBg8PT2N1ytXrqzWlW0S1fchQYIEHy0bNGiQei0ZM2b86HWbxijt1KlT2okTJ4zX69evr9b75ptvjMvkPdm3b1+4r8e0yXsjOnTooCVPnlxLkyaNVrNmTe3atWsqpuLFi0cYv+w/58+f13bu3BliuXj37p322WefGZcVKFBALe/Vq5dx2bp169T+Zvrac+fOrfZTYVhWsGBBdX3u3LkhnmfixIlqubwnhmXyXonSpUsbl8m+LmS/MX2url27hrmPhredwpM6deoQrz0wMFDLkydPiMeQ90Ls378/xOcmRYoUaltt3bo1xL7as2dP43tjWLZnzx61rFu3biEeu0GDBmq57MexsU/OmjVLe/Pmjfr8yPVChQqpx5fPdFQf37AvhyavxXTbhn4P5HMaeh+O7Ocisp9R+U6Txwy93PBeSQzRfY/atGljXObk5KQ9ePBAW716dYTxRGU/l7gl/si+B59a9+rVq9qWLVs+2jdu3Lihbdu2LcL9pVSpUh+95vD296hso5jsA40aNVLrffXVV8Zl8t7Jd5We343h7XPz5s3T7t+/ryVLlizE8t9//139Xwxru7OxIZqNQxOJzEx6rqRHTH6xk8qA0gslv6DL8Jp69eoZ15NfqKWHxXSInwz3kGGIGzZsMI7vl1/c5ddNqdwVVXIf+TVUhjXJr+SGJhPP5RdO+WU2NPkV0UCGmcg4fekRk19SDa5du6Z+pZReMAN/f39jT4e8DhmqIr/6y/1leFd0yHAT+bVYfjWOKhluYiA9Y/K65ZdsiU16AkMz/YVfSG+d6eurU6eO6lmQX3wNJDbptYgKGR4jPTfSQyi/NMtwq7Zt2xqHbIYVv/SEyHoSU1jbUvY5GR5nIL90y3tniF9eswxVlP1KhrkZyC/XEoMpeZ1Cem1MSY+BkF+dTUlvrvy6bCD7lZBf902fy7DcdJtGRN5z+fU9dDP08BlIj6uh9zc0KZYj75GB3F96mqZNmxaiV07Wk+0V+rXJe2A6nMnweRTSQyU9P1Fh+p7KsCnZJ+U9lc+3oTqcYUizvF8yJy2qpJck9DaToVzR9anPRUw+o2GJ6nskPcDSW2kgn1HpBfnUfhbV/Ty2SG9tzpw5VS+y6Xey7AMy9FuGF0oPU+j9RfY1+U6VYZTy3RvW90Do/T2m2yiy+4AMB5bvf3l+A3nvZDSF3t+NYZF9VnrwZDubvgfynPJ40f1/RRQWDk0k0oFhzLoMM5JkTIawff3112r4hPwjNhw4yvA+GVYhw1HkH4kchKRJk0YNWzQdbiJDr2QIiaEMviRFoQ+gw5IjRw7jPIGwhJ7HJgdx8o8w9Dqm82tMl0uSZyD/1GTIiMwpy5o1a4iD1NDDySJL5gY8ePDgo6EpkSFz3WSIjszLkQMYU6HnmoT1uuU5Te8ncyjkAEGSUlOSaEaFHLDKey0H4rJfyPsf1sGTHAjK/BXZX0zntYW1rsx/C03iN7w/MpxOktHr169/tJ7Eb3rQKa9TEnU54DMlw/LkMUPPTwn93IYhcKZJmOm+ZrrPRESSSTkw/ZSIzjsX+jZD7KHfMzkwlUQ29GuTH09CF2iQxE8+xzJ0Tj7TMkxMElw5sJaD0YjIcDIZcixDEkPvg4brMrRSkgFJnmRosOwr8qOOHEhHZnihvHeR2W6REZnPRUw+o2GJ6nsU1neTxGI6NzW854nKfh5bDN/J8t0fHtkXJOGXz70M6ZVhizI81XReVuj9J6LPQnS3UVS/G0MPlQy9bfX4bgxNvgvlO0iGzUsLiwxdJIotTMSIdCQHD5KUSZNeJJnALHOXJEEQkkzJHBAZzy7/gOSv/EOTHg4DGb8u/3DkF3IZxy5NJo/L+HuZ3xARwz9ueVx5nk9VKZQDk7CEt9zwy62QuRVykCnzRWQemPRcyD9G+WXb3CXp5flkfokcLPz444+q50cSKDmYke0WOp7wXl9cME0wpEdUEiT5JVnm7BkOmGTOlxx8y1w9SWxln5B9SQ7I5OA8Ou9PVEX2JM8x2WdiQ0RVDGNa4TC8+8tnWOYTSQ+3fC7ll3xJnGROVOhE3fTAWZI4SaaGDRum5qvIL/vy67vM1zHdJ2UOjnxXyDybmjVrqrmgckAujy/JYWy/pzIPKCzm/FxEV0z3M3OfzNzwPst7HF6xJhlJIKS3XT7z8h0q83HlxwyJV+aMhfWdGt7+GpNtZOnfjaEZtpv82BneHDYpOkMUW5iIEcUThuEVckJjA0lU5Jd0SahkCKMUuwhreIn8o5Fqa9Lkn6f0kkkxBJnoLwd04R1MGCYnS6Wr2PqVPDwyAVyGo4U+h5EM9TD9RTUqBz4Svxzoyi+YUfnFvUCBAmqCv5Q9Nu1dlB7H6JKiJtWqVVNDiEwPtuV5YuK7775Tv/7KaQ9kIr6Q3lQ5SJfXbtrLEt2qXobqfoZf402Fjl9epxyYy7qSwJr+SizvQ3w/T11EDLHLazbtPZCea+nFNf0B5FNkqKU0+WVehhfL51h+wQ+veqKcDylFihSqCIShSI2Q5w2LVHGTJkVyZKizDKuVz7z8yBFdhs9Q6EqfMen9iexnNLKf+9h8jz71PHrs54bvZEnIP/WdLN+pkixI0mYgwzZjWqk1tsm2kmHuoU/vIIV89PxuDGufk+9C2fby3sf1/0QiwTliRGYmB1wRzUkIPeRGEgXpuZGqc1IpznQsvwg9rE7+uRh+sZN/ysKQGIT+By09bvIrqvRWhTWfRQ4MY4v8chr6F1Y5kJAqhabCizUsUvlPfsGUKmpRjUWEjkeGTkaXVOOSg0HDAYGQ2KQSY0zIcCt5nZKMS6VJQ/zyPpv2VMjBsiTq0SGJvewLcn8Zsmkg85JCl7k3VB3r169fiOX9+/dXf//++29YKjmIlxL3hlM/GMiJemV/jMxrC2u/NfRsGD6Pkd0nZX8ynB7CQL4DQvdQSU+B3D+ix4/sAbP0gss8JFOhY4iKyH5G5XMfmc98bLxHkaHXfi6VEmXIniRXppUNw/pODus7Vb5vojo3Ma7Jd4tUL+zatatxmcTdq1cvXb8bw9rn5LtQHlMSOqlYHJf/E4lE/Pq0EtkAGU4iQyrkvCvyS6v8g5ISxFKEQ37hDT35Xw7i5EBL5oH9888/OHPmzEfFMyQZk94mGZ4h/3Tkn7GsZ5hrJo8hB1jSqyZDoORARtaXX/8kcZBk7/Tp02pIiyyTsuYyzl7OxRLTRMJAeuvkYExKAMuv99IrJUNFQpepluvyy7n8ui+TyOWfpfQsGMrgm5L5NzKXQhIo+eVa5snJQZ/MqZN5b+FNBpftLgc7P/30kxqOKL+Ayj/eyM5PCotM7pYhMlKyXMoqy3slvRthzdWIKjkvj+wfclAoQ9DkIFCGusnrlZ4W+ZVeDmrkNcmcw+iQ90Ym1UtvjPSoysGcvPdSbMP0MSXJl2FxMn9CDmJkOJ2UpZaDIdmn5T0xB3mPQ5/zzRCffF6iQ3pmx48fr+Z3ybaVIU7S8yKJiBQvCP0jSFjknEiyvmwL2ZclcZIDUMN588IjnwkZris9HDLUUA4mpRBB6ANtmT8mJbWlpLoMZ5b3SdaTA9ConuA6NPkcyOPK+y7PL/FL0ZGYzImJ7GdUEhDpkZZ5dTKnTL4LZZvHxXsUGXG5n0uCLb04ocn7L8V+ZNSAlK+Xz578P5DhpvI9Jb1K8h7JvFbDd6q897JvyfeN9IzKNgw9Z0tvMkdSvsNlbqP0gsn3r+nc3JgM/4zJd2N4+5z0tMm2lphlBIpsW4lVhgnL+mGdNoMoJnQv3cjGZkutVq1a2m+//ab9888/mpeXlyrFLGV4f/75Zy1lypRh3kdKoocuHW9ojRs3VqWcHz16pB7r1q1bquS1aRlvaZ07d9b+/fdfYzly0xLVclnKJUtpXilhfv36dW3BggVa0aJFP1l2WcofX7hw4aPlUrp806ZNxutSfnvSpEmqLLCULj9w4IAqtSz3N5TPNrR69eppFy9e1Pz9/UOUNw5dvl6alGMeMGCA2p7y+h8/fqz9/fffWpEiRSJ8H6Q0+/bt29V78OTJE1Wq31DWPXSJ5rBet5TmNy3rLi1p0qTa4sWL1ekEZFvKZUO58ciWaA6vLPnu3bvV48ppDeR6x44dVZlrKf8vr10eP6yYxIwZM8J8f0KXbq5QoYIqOy3bUfYVKc0e1mM6ODhoQ4cOVeW0/fz8tNu3b2tjx441llgPbx+IKCZDeWx5LyOzncJjesqE8F67oZx3eCXmpRS6bFN5bQ8fPtRmzpypTtUQmf2+cOHC2vLly9XnUN4b+Vz++eefIT5L4bUyZcpohw8fVp+Pe/fuGU9tYfp5zZIli/r+kM+ofFafPXum7dq1S6tatWqslE6X8uBStlxK5j9//lx9l+TNmzdGn4vIfEbllBd79+5Vr10Y9s3Q5etj4z0K63skrBbZ/Tyq5evDI++pYT353lizZo329OlTtR9JvCtXrtSqVKliXEde7/z589X3l3yPyXe4bMfQn+2I9vfIbqPwytdHdh+Q/WrZsmXa69ev1Xej/H+R/V2YnvrEnN+N4e1z0uR/sXx3yHsu772U89+xY4fWpUuXSL3PbGyIZLP7cIGI4jEZhjN16lTV0xK62hwREZGlkWIz0lsmJ+GO6UmwiSwVEzEiC3Du3DlV4l2GJREREVkSGUZsen4vGZ4qp1opXry4OiWL6W1EtoRzxIjiKZlHJuPoZay6nM/FMC+AiIjI0uZGS9VEKbMvRWVk/qz0hMm8LiZhZOt0Hx/Jxsb2cTOMyX/x4oU2ZswY3eNhY2NjY2OLTvvyyy+1kydPqrlcMk9Q5gD36tVL97jY2KBz49BEIiIiIiIiM+N5xIiIiIiIiMyMiRgREREREZGZsVhHLEmXLp06+SwREREREdk2d3d3dbLwiDARi6UkTM58T0REREREJNKnTx9hMsZELBYYesJkY7NXjIiIiIjItnvD7t+//8m8gIlYLJKNzUSMiIiIiIg+hcU6iIiIiIiIzIyJGBERERERkZkxESMiIiIiIjIzi5sj1rNnTwwcOBBp0qTBuXPn0KdPH5w4cSLMdbt06YJ27dohf/786vqpU6fw/fffh1h/4cKF6NChQ4j7bd26FbVr147jV0JEREQUkqOjI9KmTQt7e/5WThQfaZqGZ8+ewcfHx7YSsebNm2PKlCno3r07jh07hn79+mHbtm3IlSsXnj59+tH6lStXxooVK3D48GG8e/cOgwYNwvbt25EvX74QpSS3bNmCjh07Gq/7+fmZ7TURERERiVSpUmHMmDFIkCCB3qEQ0Sfs3btXdehIYhZddpLYwUIcPXpU9WZJL5iws7PD3bt3MWPGDPz444+fvL/8uvTy5Uv07t0bS5cuVctkAyZJkgSNGjWKUYlKLy8veHh4sGoiERERRZkc0wwePBgpUqTA7Nmz+aMwUTzutc6dO7fqINq3bx8WLFgQ7dzAYnrEnJycUKxYMYwfP964TDLQnTt3okyZMpF6DFdXV/U4L168+Kjn7PHjxypJ2717N4YMGfLROkRERERxRX4UloO7X3/9FdeuXdM7HCKKwI0bN9TfFi1aYOXKldEepmgxA5DlFyLJQCVhMiXXZb5YZEivmQxJlOTNdD6YzCOrVq2aGrpYqVIlNVQxorHZzs7OKtM1bURERETRZTiWePLkid6hEFEkXLlyxZijRJfF9IjFlCRZLVu2VL1fpt39q1atMl6+ePEizp8/j5s3b6r1pHcsLDJ0YMSIEWaJm4iIiGxjaKIICgrSOxQiioTAwMAQn12r7hGT6iTyglOnTh1iuVx/9OhRhPcdMGAAvvvuO9SsWRMXLlyIcF1PT09V+CN79uzhriPDI2XMp6GlT58+iq+GiIiIiIhsmcUkYgEBAar8vAwhNJAMVK4fOXIk3PtJqfuhQ4fi888/V/f/FEmqkidPjocPH4a7jr+/v5p4Z9qIiIiIyDZJ3YIGDRrAGiVLlkxNBcqcOTNsQfLkydXrNUdHi8UkYkJK13ft2lXN6ZIJrbNmzYKbm5uqfCgWL16McePGGdf/9ttvMXr0aHTq1Am3bt1SvWfS5D5C/k6cOBGlSpVSO1fVqlWxceNG/Pvvv6osPhERERGFT+bHSIGR27dvq1MFyQ/ZMv++bNmysfL4coy3fv16xBfDhw/HmTNnPlou9QqkxkBMErmwmhSD0NsPP/ygjo/lPdbTnj17MHXq1Fh9zLD2r+fPn2PJkiUYOXIk4ppFzRH7448/kDJlSowaNUrt8GfPnlU9XYaJrZkyZUJwcLBx/R49esDFxQVr164N8Tgyv0s2rozDLliwINq3b6+qFUkhDznPmPSgSa8XEREREYVPjrGkiJkcS8kce/nBW0YrSa+CLQldTC46OnTooJJYU69evQpzXSkqZ0jWTEl1cBlFFlXh3S9hwoTo3LkzatWqBVuycOFCNZJORtZJVfW4JO8gWwyau7u7JuSvnnEk9HDXyn3ZVCvborFWplkjrXTTBlqpxvW0kg3raiUa1NGK1autFa1bSytSp6ZW+PPqWqFa1bSCNapoBapV0vJXrajlq1xey1OxnJa7QhktV7nSWs4yJbUcpUtoOUoV17KVKKp9VryIlrVoIS1L4YJa5kL5tUwF8moZ8+XRMuTNpaXPnVNLmzO7liZHNi11tqxaqqyZtZRZMmkpMmXQkmdIryVLn1ZLmjaNliR1Ks0jVUrNPUVyLVHypJpb0iSaa2IPFXuCRG6ai6ur5pwwgebo4qI5ODlp9o4Omp29ve7vMRsbGxsbW1y2zJkza0uWLFF/9Y4lsi1x4sTq+KdixYrhrjN//nxt06ZNIZY5Ojpqjx8/1jp16qSuN2nSRDt//rzm4+OjPXv2TNuxY4fm6uqqDR8+XAutUqVK6j4ZMmTQVq1apb18+VJ7/vy5tmHDhhDbbuHChdr69eu1wYMHa48ePVLrDR06VHNwcNAmTpyo7nP37l2tQ4cOIWKbMGGCdvXqVe3t27fajRs3tFGjRql45bb27dt/FI8sk9tEgwYNjI+TPn167ffff1fP8+bNG+3EiRNayZIlw91Ooe8fusnzyGuoV6+edunSJS0gIEC9Xk9PT23IkCHa4sWLtdevX6vXLes3btxYu3jxovbu3Tu1Tv/+/UM8Xnj3C93kvZH3ynRZkiRJtGXLlmlPnjxR79m1a9eM23HXrl3ajBkzQqyfIkUKzc/PT6tataq63qNHD3UfX19f9d6sXr36k/uaxBea4f3Oly+ftnnzZs3b21s9nnyOkidPHuI1RHX/kibvv2EfjepnNrK5gUX1iFHE3JMnQ+PvB8CaBQcFQQuWX4CC1V/pATVcNv5Vyz78/bBcrRfeOibrBqvbI348/3fv4PP6Nd6+eg2fV154+1r+friulnup64HsVSUiohhwTphAl+f1930XqfXevHmj5sk3bNgQR48eDXM00W+//Yb9+/erkUyG4mp169ZV53aVytWyfMWKFWo6iQwRkzL+FSpUUHUAfvrpJ+TJk0cVRuvYsaO6r5znVU5nJFNIpEaArCvF3OQcsNKbJCOdDD07MuXk3r17qFixIsqVK6dOvCtDJiUemZYiw/7mzJmDHTt24P79++o+8nqkZ0pGSRUoUADz5s1TyyZNmqTizZ8/vxqNVb16dbX+69evP3rNMvVFTvQrj1m/fn31uosWLRrhqZEiQ7aZVAHv0qWLGj5nGBH2zTffqNFihqF08lwyikxGgEnM8ppl+KjcR6bxGIS+X1hk+4ausSDTfvLmzYvatWurYnpS4E56zgzv9y+//KIK5Rn2hzZt2qhtIdXI5ZzA06dPR9u2bXH48GE1/0ye41P69u2LnDlzqgrnw4YNU8ukuF7ixInV48rzfv311yoOOV2VvH7pmY3O/mVw/PhxtW5YJ2yOLUzErIifjw/Obt0JO3t7tYOpv/Z2sLP78NfeHvaG5SbLwl83jHVC/A25vult8mUT0WMblkf1S8newQFwgEXw8/FVidnHyZoX3r58ZbLsfeIm1995v9E7bCIiiidJ2Pjje3R57sElq0QqGZMpHpK0SLLSvXt3nD59WiUgcoJbQ5VqSZauXr2qDrwlmRFy0Lt69Wq8fftWHVzLsLh169bhzp076nY52Dbw9fVV00xMh/61bt1aHT9IQmIgjynD+OT0Q5JYGQ6qv/rqK/VjqpwkWw7GJZmR6tdC/kpV7fLlyxtPZzR27FjjY8qcKDlYl9MfSewyB06ST0n8IhqK2KpVKzWVpkSJEsZhbYYTAEdEEobQpy+QhOfu3bvqsgwB7dmzpzrVkilJRKSOgsGyZcuwa9cujBkzRl2/fv26ehwZZmeaiIW+X1ikhoIkpaZkKpDMkzMkaKZzx+R9lERMCpfIeyxkH1m0aJHxvvK+//XXX2pbynsuU40+xcvLSyV2cuJk023fu3dvFYvMYzOQ2hCSgOfIkQOJEiWK8v5lIK+7SJEiiEtMxKzI68dPsXTgUFiaj5K8j5I2Sdg+vY5ctg9vHfX3wzphJqEf3+/j53yfOMo/R9ckieGWOPH7v0n/u+ya2EM1B0dHuLgmVC1p2sidcFwEBQaqRE21D8mZSuSMvW0fkjfD7R+uy/2IiIjMTQ5w//77b9VzULp0adVLIgmPJEmGg37prejWrZtKZlKlSqXWkd4qce7cOezcuVMlbtLLJXP116xZE+7cKFGoUCHVCxO6anWCBAmQLVs2YyJ26dKlEHOo5GDb9CBcRstIL5HEZNC8eXOVvMnjyEG89L5JEhAVhQsXVslBVOcWSY+ObAtTpkmQnAc3dBImTp48GeK69PJIcQ1Thw4dQr9+/dRxjKGeQuj7hUV6mCQBNSXF8mRuoPS8yfu1YcMGYwVziXHp0qUqGZJETBIZ6UWUnkEh740kbjKfcOvWrapJT5UkRNEh+0KVKlXCrGAu76HEF9X9y0BiksQ9LjERI92pYX9WdgLLBO6J/kvUkniETNw+JGzv/8qy95ddXF1VAidDTKVFxbu3b/H25ftk7aNEzWS4pGlC5/fWJ85ePxERxYz0SEnPlF7PHRVy8C0Hu9KkF0Z6yGS4myERkwp0EyZMUImaDJOTc7YePHhQ3SZJQY0aNdRyOd9rnz59VK+UDB2UitdhkQRJemOkZyw0Ga5mELr4hBxvhLXMMDpH4lu+fLmqjCgH7TLsUHrDZJhdVEQ3qZAhjBH1nIX3uNLDFB2RuZ8MPUyaNGmIZZI8SU9ZnTp11HsnvW8zZ85UPW6GxFt6uaT8u/RUSs+boTdKesEkgZOey5o1a6qhkTKEUnoPwxrm+SmyL2zatEkN2QxNKnhGZ/8ykGGTpvtTXGAiRhQHZIihtOf33o85jwxHZ+f/ErfEHxI2YwL3X+JmmsglTOyh/oEkcHNTLXmGdJF+vsCAgI963v67/CF5k6RNhlF+GFIpTebpERFR/EuI4ot//vlHzRszkCGC0msiB+VlypQxnnbIlMwXkiYH5tJj0qhRI1WqXIajOci0BBMyBFLmd8kcqdg8l6scrMtzm54KKfS5s8KKJzTptZIeQUlg4rriXlguX76s5sSZkusyPNO0unhkSM+ezPEKK0GTBFvagQMHVG+nIRGTXkfpbZNTTskwTRk+aEqGX0rytmvXLpWwS++U9JB+6jQF4e0LTZo0UUlV6GGd0d2/DKQnb+/evYhLTMSI4gkp7uH15KlqkSXDJhO4u4fZ62ZM5Ex74D6s45TABY5OTvBIkVy1qPD18v5vyGSouW+he90Mwyr9o/nrIBERxV/SYyDDz6SYgSQfkhQVL15cDU0MPTROeklkXpAc9JrOUypZsqQqqiBDxiSxkp4KmV8lyYSQA2wpnS5zyWQYofSaSK+VHPTLc0jhBpkPJAlT48aN1flhDYU3okrmUskcJknyTpw4gS+++EIdsJuSeLJmzaqGxMnzymsOXaRE5np9//33KvkcPHiw6pmRIXoyzFCKmoRHTqUk5f9NyePLvKiomDx5sopfCpjI3DdJfiUZkvllUSU9gzKXTmIzDOeT5El6JGXop8yvkuIrhvfLwFC0Q3rdTBMs2aafffaZKpjy8uVL1asmPyjLPMJPkW1vOPev9KxJgi89cZLwyTaX916WybBV6cmUZFj2x6juXzIHUIZkSmEReR/jEhMxIgsmQyp8vbxUw517kb6fJGIhhkqGkaypXjjpgUuaRF129fBQ903o4a4aMkYtyTQWKjHOc5PetveXTYdPPva8pZI9IiKK3+Rg+NixY2puk8zHkaIIUlhChiaa9ioJGbYoCYkcvMtfA5l/JVUNZf6SVK+T3goZCmg4n5Y8lgxjkx4WqXgnl6UgiNxHquPJHDVZLsmX9LBEdT6XKRniJr0kkkBIgiFz36RCoAydM5C5UZLwycmFpcdLClGYJpZChj/KMDhJiDZv3qzmmUkvYa9evSJ8fkNBC1NSTEReZ1R7sWSum/T+yLlxZXtLwho6zsiQ3i3pdZLHmzt3rlomiackZ1myZFHDJaVHTBIfU5IYTZs2Tf2VoasGkszJ9pNtmiBBApX8fvnll2r7fIoUTpHXIOvK3C15ftlfpLdPtpEkW/K+yTLZf6T3L7r7lxQbkeGUhiG0ccXuQx17igF54+SNljc4NrvIieITqVgpCdh/QyRD9sIZErfQvXAy5DKq893+nPgzjq3bFGevhYgovpFf+eWgXw6cTavQWQsp6S7JkgxP/NQQNIpfpNdKhh7KUL3QJ5COaH+W+W4y90sSQ0tz5MgRVWZfEsnofGYjmxuwR4yIIkXmhqn5Yi8/XWnIlHPChB962iQxS2LS6/YhkTMpWpI4ZUokTp0SzUd+j/zVKmH1iAnwevoszl4TERHFLRlCnyJFCtULIb0hf/75p94hURRJr56UgpfiGzIcMyLS+5c8eXJVtEWGYVpiEpY8eXLV0xpREhZbmIgRUZyS+WHSXj58fyLPiMgpAiq2aYHaX/0PeSuWw8D1y7F2zCR1fjwiIrI8MudK5uHIkEUZxhdRQQWKv37++edIrSfDBKXAhcz5atq0aaQfP2PGjBEOTzQ9n1pck7lihnPexTUmYkQUb2jBwdi3ZAWuHDqKL8cNQ8a8udF20mgUqF4Z68ZMUvPLiIjIcsiQLekVI9sg86ui834/ePBAnX8totutERMxIop3Ht/wxPTWXVC9S3tU79YRhWtVw2fFCquhiv/si9uJs0RERGReQUFBEZ5DzVq9P4MdEVE8ExwYhO2zF2B6my549O9NVWa/8y+T0GL0D0iQyE3v8IiIiIhihIkYEcVr9/65iqktOmLPgmWqFG3JhnXxzbplyFGquN6hEREREUUbEzEiivfkPGR/TZ2JXzv0wLO795A0bRp0/20GGg3uD+eECfQOj4iIiCjKmIgRkcXwPHMek5u0w6GVa9X18q2aof/qJchSqIDeoRERERFFCRMxIrIoUgp/3difMKdbX7x6/AQpM2dEr8Wz8EW/HnBwctI7PCIiIqJIYSJGRBbp2pHjmNSoNU5s3Ax7BwdU7dwOX69aiPS5c+odGhERmYmmaWjQoIHeYcQ7S5YsweDBg2HNVqxYgf79+8OSMREjIov1zvsNVg4ZjYV9B8H7+QukzZENfX+fj+r/66iSMyIiilsLFy5UyZA0f39/3Lx5Ez/++CNcXFxgK6/btG3ZskXv0FCwYEHUqVMH06dPNy7LkiULli9fjvv378PX11edHHnDhg3IlSuXcR3T1/HmzRtcu3ZNvc6iRYtG+rnbt2+Ply9fxurrqVSpkoopceLEIZaPGTMGP/zwAzw8PGCpmIgRkcW7uHu/6h07v2MPHJwcUbt3N/RZOhepsmbWOzQiIqsnyUeaNGnw2Wef4euvv8b//vc/jBw5Erbyuk3bl19+Ge76jo4fn77XKZpD6iO6X58+fbB69Wq8ffvW+Lw7duxQiUzjxo1V8tWiRQtcuHABSZIkCXHfDh06qNeRL18+9OrVC4kSJcKxY8fQtm1bxDeXLl1S5x5r06YNLJnGFrPm7u6uCfmrdyxsbLbein5RUxt9aJs2+cIRbcLJvVrFdi01Ozs73eNiY2Nji6hlzpxZW7JkifqrdyxRaQsXLtTWr18fYtmaNWu0U6dOGa8nS5ZM+/3337V79+5pb9++1c6fP6+1bNkyxH327Nmj/fzzz9qPP/6oPX/+XHv48KE2fPjwEOtkz55d27dvn+br66tdunRJq169ujr+atCggXGd/Pnza7t27dJ8fHy0Z8+eaXPmzNHc3Nw+infw4MHao0ePtJcvX2pDhw7VHBwctIkTJ6rnvnv3rtahQ4cov+7QTXTv3l3buHGj9ubNG/V6pJ05c0br3LmzdvPmTS0oKEitmzFjRm3Dhg2at7e39vr1a23VqlVaqlSpjI8V3v1CN3t7e/Wa6tSpY1xWqFAhFUumTJk+Ga/ptjS0RYsWqZiSJEkS4f0rVaqkhWZ4D52dnbVJkyapfUC2xdGjR9X6hvtKbH/++af24sULdfvFixe12rVrq89DaLLtDfeT927//v3x7jMb2dyAPWJEZFVO/70dkxq1weWDR+Dk4oIGA/uix4KZSJY+rd6hERFFiauriy4tJqQnpWzZsmqYokGCBAlw6tQpfPHFF8ifPz/mzp2LpUuXokSJEh8Na5NenFKlSuHbb7/FsGHDUL16dXWbnZ0d1q1bpx5Xbu/evbsaAhlye7li27ZtamicPHazZs3U/X/55ZcQ61WtWhXp0qVDxYoV1RyjUaNG4a+//lL3k8eePXs25syZg/Tp0yOmRowYgfXr16NAgQJYsGCBWpY9e3Y0adJE9U4VLlxYvbaNGzciWbJkahhejRo1VO/iqlWrQjxW6PuFNyxRerlOnjxpXPb06VMEBQWhadOmsLeP+qH/1KlT1fA/iSsihw8fRt++ffH69WtjD+FPP/2kbpP3oEyZMmjZsqWKUXrstm7dql6TmDlzphrOKu+JbKtBgwap4ZEyhFJer8iZM6d6THkOg+PHj6NkyZJwdnaGpdIli7Smxh4xNrb42Uo3baCNO7ZL9Y7JX7mud0xsbGxskfl13dXVRQvWNunS5LkjG7f0TgQEBKieHOmpEoGBgVrjxo0jvN+mTZtUD4lpj1jono1jx45p48ePV5dr1Kih+fv7a2nTpjXeXqtWrRC9OF26dFE9Wq6ursZ1pFdF4jH0Lkm8np6eIUZKXL58WfW0mfYqyetp0aJFpF63aZOeNsM6YsqUKSHuJz1Efn5+WooUKYzLpGdPHitDhgzGZXny5FH3L168eLj3C6vJtpDHCr28Z8+eqqdJerakx3DIkCFa1qxZI9Uj5uLiom4bOHDgJ/eH9u3bqx4502XS2ycxmb530nbs2KGNHTtWXT537pw2bNiwCHvaEidO/NFtBQoUiFRvnzk+s6aNPWJEZPOOrtmIn5q0xY1TZ+Di6opmw79Dl1lT4JEqpd6hERFZjT179qgeGulNWrRokSrwIL1XBtILM2TIEJw/fx7Pnz+Ht7c3atWqhUyZMoV4HLnd1MOHD5EqVSp1OU+ePKp3RJYZHDlyJMT6ss65c+fg4+NjXHbo0CE4ODiEKEohc4uk+IPB48eP1Xwpg+DgYBWn4bk/9bpNm/SmmTLtmTK4ffs2nj17FiJueW337t0zLrt8+bLqoZPbwrtfWBImTAg/P7+Plv/666+qN6l169Zqu0lvoWwHQ49jRKTHTphus6iQHi6ZpybFP+S9N7RKlSohW7Zsah0pLCL7yMGDB1UvotwnMqTwiKE31BJ9PGuQiMiKvLj3ALM69kKFNi1Qp2935ClfBgPXL8P6cZPVMEYiovjIx8cPidya6vbcUSHDCaVogujUqZNKhuSvYSjewIED1XCyfv36qYRH1p82bdpHw8kCAgJCXJcD/+gMpfuUsJ4nOs9t+rojWicyyyIjMveTRM3NzU0V8wj9mmSonwzBlCZJjwzjlL87d+6M8DENyaCnp2e04paCH4GBgShWrJgaIhk6JjF//nwVjwxfrVmzpiq9P2DAgI+GlYYmwzkNwy8tEXvEiMjqyT/U/UtXYkqz9rhz8R+4enig9YSRaDd5LNyShqwYRUQUX0hCpEeL6fftuHHjVGlxmRsmypUrp+ZASfl06fWSEvcy3ycqpIcoY8aMqlfHoHTp0h+tU6hQoRC9I/LccvB/9epVxFeG15YhQ4YQyU/SpEnxzz//ROmxzp49q/7mzZv3k+teuXJFJW2fIgm0zPv6VMImZA6f9ECaOnPmjOoRkx5GSVxN2+PHj43rSY+gzM2TeXCTJ09G165djY8pQj+ukDmH0psoPZiWiIkYEdmMJ563MaNtN2z5ZS6CAgJRqGZVDFy/HPmqVNA7NCIiqyGFGCT5kfLn4vr166rQgxRryJ07tzrYTp06dZQeU5IAGdq2ePFiVeyhfPnyGDt2bIh1JNF79+6dWkeKhlSuXBkzZsxQhUGePHmC2CbFJeR1mLbkyZNH+XHktUlPocRfpEgRVWhETsi8d+9eVeQkKqRHTO4j28dAklM5Z5gkOJLgyXBA6bGUJgmyKSn0Ia9Dho3KsEV5L1u1aoUePXqoZOxTbt26BXd3d1UQRbaFDJWU93/ZsmXqNTVq1Eid00xe43fffafOd2YoCCI9YXKbbIMqVaqoBNUwJFOGi9atWxcpUqQIkTxWqFAB27db7ugWJmJEZFOCA4Owc85C/NyqMx5evwH35MnQafpEtBwzFAncE+kdHhGRxZMkTIaUSeVD6Z2S3rHTp0+roWeSXDx69EglBlHtaZODeDmwl0p5v/32mzqZb+j5QjL3TIarnThxAmvWrMGuXbvQu3dvxIXatWur12LaZI5TdDRo0EDNCdu/f79KzKTXUM71FR2ybWQumGlPkyRIw4cPV+cEk/dChorK9dDJrMzxk9chvWWzZs1SQwelKuGKFSsi9dwy/0zuJxUfJSmUfUB07NhRJWLS0yW9k/L+lyhRAnfu3DH2dknlREm+pJqiJN09e/ZUtz148EDFOmHCBNWDZhiuKIlww4YNMW/ePFgqmX0XvZl3ZCSZv5eXlyrtKZMP9ZI2bTKMHNkq3NvDm2QZ3tzLiCZlRvWxIr5P1JZH9DzmeqzgYO0Tf4PV45r+jc59Pn3f8O9jWC869/n4vpG/z8ePEbX7+PsHRntCcFQ5ODnh815dULlDa9g7OODVo8dYNWwsrh05YZbnJyIyyJw5M0aPHo2hQ4eqHgCi6JIhoZLsSCJ39OhRWKvu3bur5FyS7/j2mY1sbsBiHVYkSRI3dOmqz85IFJu/pL569RYvX77BixfSvNXllyaXX4Rz2c8vIGrPFRCAv6fNwqU9B9Fy7FCkzJwR/5s7HYdWrsVfU36Bv++7OHudREREcUGGZ7Zr104N47NmAQEB6NOnDywZEzEr8vTpawz5YWmYt32oPBrObXbRvC3qj2nO54qLx5TlcpP8lWpKcjnsv3K7nfGv4bJdFO7z330juk9M7hv2feLivmFNsA2PrJs8uYdqUSWTzEMnaK8+XH6/zPvD7W9NLr/B7fMXMaVZO3zRryfKt2qGci2bIFfZUljxw2jcOhuynDIREVF8t2/fvjh53M2bN6t5WWGRIi3jx4+HucyfPx+WjomYFXn2zAvjxv2hdxhE4XqfyIafxDk42CNhQmckS+aOpEkTIVmyRCaX5a8bkiZzN15OZnJZEjhXVxfVMmSI2q+AMlxS9bq9fAMf/3NImCotgjJ4oNmOn3D19CWc3HkQz568ipVeOCIiIkvVpUsXNU8vLC9evDB7PJaOiRgRmY3M/Xo/Hyz8dby8fPD48asoPa4kce7uCcNJ4P67nDTUcvmbKFFC1XP3cS/c+3K5hWtmR4ua2SPshfuvt+19MvfS5HJ4vXCvX/uYbS4cERFRbJDCGRR7mIgRkcWThEYSOGm3bv13TpLIcHZ2fJ+kfeh1MyRocjlX0bwoWrUc3BO5IIF9EN49fwKHAN8we+HSp08e7V640HPhQid2oS+zF46IiMjyMREjIpsmVRqlBy7sXrg/4ZYkMZoM/VadcwxIgruXLmPF9z+oc5JJL1xYCZzp5aRhLA+/Fy5yotoLZ1jGXjii+Mvw2ZQT3xJR/Cfl8w1FxqKL5eutqHw9EcWdIrVroPEP38A1sQcC/PywdcZc7Fu6ElpE4ywj2QsX1nDKpOEsj0rhk7B64e7efYa9ey9g754L2LPnPO7ceRrtxyOi2CPzbuT8SHIepfXr1yMwMFDvkIgoDPJ/OFWqVGjevDkSJUqkzncW+vMa2dyAiVgsYCJGZBs8UqZA85GDkadCWXX95qmzWDlkDJ7fu2+W5zfMhftUL1ySMBI46YULy40bD41J2Z49F/DwISdbE+klf/78+Prrr+Hk5KR3KET0CXLSazmZ9NOnH/+gyUTMjJiIEdmWUo3rof63fZHAzQ1+Pj7Y9NMvOLJ6PeIzJydHlZAVKJAFVaoUQOUqBVGiRA44OobsYbty5R72fkjKpOdMTotBRObtGUuZMmWEp18hIr3npXvh9evX4Q73ZyJmRkzEiGxP0nRp0HLMUGQvUVRdv3roKFYNH4fXjy1nqJ/0rpUvnxdVqhRElaoFUaTIZ2rumqkLF24Ze8z27buo5psRERFR+JiImRETMSLbJL9Yywmg5UTQTglc4OvljfXjp+DUX1thiZIkcUPFivlVj5kkZgULZv1ojtnZs57GHrP9+y/C29tXt3iJiIjiIyZiZsREjMi2pcqaWfWOZS6YT10/v3Mv1o6eiDcvXsKSpUjhgUqV8qNq1UKoXKUA8uTJGOJ2qRR18uS/xh6zgwf/URUdiYiIzCl79rT47rumGDBgAV6/fmtRuYFmSa1nz56ap6en5uvrqx09elQrUaJEuOt26dJF279/v/bixQvVduzYEeb6I0eO1B48eKD5+PiodbJnzx6lmNzd3TUhf/XePmxsbPo0ewcHrVrX9tqPp/drky8c0Ubu26wVqFZJ97his6VJk1Rr2bKiNndub+3a9TlasLYpRHvnt07bf+BHbdSo1lqVKgW1BAmcdY+ZjY2Njc26m4ODvXbo8CT1f2jJ0v66xxPF3ED/YCPbmjdvrr17907r0KGDlidPHm3OnDkqwUqZMmWY6y9btkzr0aOHVqhQIS1XrlzaggULtJcvX2rp0qUzrvPtt9+qZfXr19cKFCigbdiwQbtx44bm4uISFxubjY3Nylu6XDm0AWuXqmRM2pfjhmkJPazzuyFDhhRa27ZVtAUL+2met+Z/lJj5+K7Vdu0eqw0d2lIrXz6v5uTkqHvMbGxsbGzW1QYPbqb+57x8tVLLmDHsnMDczSoTMekBmzFjhvG6nZ2ddu/ePW3QoEGRur+9vb32+vVrrW3btsZl0hM2YMAA43UPDw/V29aiRYu42NhsbGw20BycnLTaX3XXJp09qJKxoTs3arnKltI9rrhuWbOm1jp3rqktXTZAu3d/0UeJmfeb1drWbaO0775rqpUsmVP9iql3zGxsbGxsltsKF/5M8/Nfr/7HyA+DescT1dzAYuaIyTk1fHx80LRpU2zcuNG4fNGiRUiSJAkaNmz4yceQk649efIEzZo1w99//42sWbPi5s2bKFy4MM6dO2dcb+/evTh79iz69esXqdg4R4yIwpKpYD60GjsMKbNkUtcP/7Eem36aAX9f2yhwkTNnelStWlCVyq9cOT9SpUoS4nYvLx8cOHBJzTHbvfs8zp3zVAVBiIiIPsXFxQnHT0xRp2VZt+4wmjYZj/gisrmBIyxEihQp4OjoiMePH4dYLtdz584dqcf48ccf8eDBA+zcuVNdT5MmjfExQj+m4bawODs7w8XFJcTGJiIK7c75S5jcrB3q9O2Bim1aoGzzRshVtqQ6CbScDNraXbt2X7XZs7eoCpN582Y0Fv6QIiBywukvviihmpDS+FIiX6oySmJ26dKdcM/RQkREtm3UqNYqCXv8+CW6/28mLJHFJGIxNWjQILRs2RKVK1eGn1/MqnoNHjwYI0aMiLXYiMh6Bbzzw8Yfp+HSngNoMfoHJM+QHj0WzMT+pSuxZfocBPr7wxZIQiWJlbQZMzap85UVKpTVeHLpihXzIWnSRGjYsLRqQk4mLSeV3rP7fbn8q1fv6f0yiIgoHihfPi8GfNNIXe7W9Rc8e+YFS6VZQnNyctICAgK0Bg0ahFi+aNEiVWAjovvKHDApyFGsWLEQy7NmzarGb0oxD9Ple/fu1aZNmxbu4zk7O6sxn4YmxT84R4yNje1TzcXNVWs+8ntjIY+BG37XMuTNrXtc8aHJfLESJXJogwY11bZsHanmk4WeYybzzpYt/0bNQ/vsszS6x8zGxsbGZv6WKFFC7d8b89T/hd9+66N7PDZVrGP69OkhinXcvXs3wmIdAwcO1F69eqWVKhX2RHkp1tG//3+lLmWDsVgHGxtbXLY8Fctpw3dvUsnYxDMHtFo9u2gOjqwoaNqkwmK5cnm1IUNaaDt3jVEVGEMnZrduL1AVG9u1qxpvKmWxsbGxscVtmzOnl/ofcNPzN83dPaHu8dhU+XpJktq1a6flzp1bmz17tipfnypVKnX74sWLtXHjxoUoTS/l7hs3bqylTp3a2Nzc3EKsI49Rr149LX/+/Nr69etZvp6NjS3Om2tiD63NxFHG3rGvVy3S0mT/TPe44mtzcXHSKlcuoI0c2Vrbt3+COmdZ6MTs+r9z1TnOvvyykjrnmd4xs7GxsbHFbvviixLq+z4waKNWsWJ+3eOxqURMWq9evbRbt26pBEt6yEqWLGm8bc+ePdrChQuN1+XEz2EZPnz4Ryd0fvjwoUry5ITOOXLkiKuNzcbGxhaiFa5VTRt1YKtKxn48tU+r0rG1ZmfPsu6faq6uLlqNGkW0cePaaYePTNL8AzZ8lJj9c3mWNnNmD61p03JaihQeusfMxsbGxhb9ljy5h/bg4RL1/f7TT510j8emytfHZyxfT0Qx4Z4iOZqPGIy8lcqp655nzmPFD6Px/C6LU0SWu3tCVKiQD1WkVH6VAihS5DNVEMTUhQu3jIU/9u27gFev3uoWLxERRc0fq79D06blVNGn4sX6wc8vAJaeGzARiwVMxIgoNpRsWBcNBvVDgkRu8PPxxd9TZ+LwqnUs4R4NUoGxYsX8H6oyFkDBgllD3C7nKzt71vNDYnZenc/M29s2zu9GRGRpWrWqhGXLv0FAQCDKlP4Gp0/fQHzGRMyMmIgRUWxJmjaNKnOfo1Rxdf3akeNYNXQsXj1+ondoFi1FCg9UrlxA9ZhVqVoQuXNnCHF7YGAQTp3619hjdujQP/DxidmpToiIKObSp0+OCxd/QZIkiTBs6DKMGbMK8R0TMTNiIkZEsUlOflzuyyb4ol8vOCdMAF/vN9gwYSpO/rlZ79CsRtq0yT4kZgVUYpYtW9oQt/v7B+DYsWvYu+eC6jE7cuRKvB4GQ0Rkrf8Pt24biRo1iuDYsasoX+5bBAUF6x3WJzERMyMmYkQUF1Jkzogvxw5FlkIF1PWLe/Zj9cgJePP8pd6hWZ2MGVMakzLpNcuUKWWI29+988fhw5c/JGYXcPz4NTVEhoiI4k7PnnXwy8we8PX1Q5HCfXHt2n1YAiZiZsREjIjiir2DAyp3aI1avbrA0ckJb1++wprRE3F+xx69Q7Nqn32WxjiMURI06UEz9fbtOxw8+I+xx0yGNVrCr7RERJYiR450OHN2OlxdXfBVnzn45Ze/YCmYiJkREzEiimtpc2bDl2OHIX3unOr66b+3Yd24KfD18tI7NJuQK1cGY4+ZDGlMmTJxiNu9vHywf/8l/LnxKObP38ECK0REMeDgYI8DB39E6dK5sWPHGXxea7hFfa8yETMjJmJEZA4Ojo6o0aMTqnVup3rKXj95ij9GjMeVA0f0Ds3m5izky5cJVSUpq1IQlSrlV1UaDZYt24POnaZz6CIRUTR9/31zjBnbFq9evUHBAn1w794zWBImYmbERIyIzClTgbyqdyxV1szq+pE1G7Bp0gz4+fjoHZpNkvOVFSqUFXXrlsCQoS3g5OSIbdtOo1nTCXjzhiXxiYiionDhz3Ds+GT1Xdq2zWQsX74XloaJmBkxESMic3NK4ILaX3VHpbYt1fXn9x5g5dAxuHnyjN6h2bRatYpizdrBcHNLgJMnr+OLOiPx9OlrvcMiIrIILi5OOHFyKvLnz4w1aw6hebMJsObcwN6sURERUawIeOeHPyf+jF879sSL+w+RPEM69Fr4K+p/2xeOLi56h2ezpCesapXvVfJVvHgOHDo8URX+ICKiTxszpq1Kwh49eomePX6FtWMiRkRkwW6cPIOfGrfB0TUb1XXpIRuwejEy5s+rd2g268SJ6+pcN56ej5E9ezqVjBUpkk3vsIiI4rWKFfPj6/4N1OVuXWfg2TPrL0bFRIyIyMLJ3DA5v9i8nv1VAQ+ZO9Zn6Rx83rubKvBB5nf9+gOUKzsQZ8/eROrUSbF33zhUq1ZI77CIiOIld/eEWLion5pzO/+37fjrrxOwBUzEiIishFRPnNSoDU5v3v6+wuL/OqLvivmq9D2ZnwytqVxpMHbvPgd3d1f8vXk4WrSooHdYRETxzpQpXZA1a2o1kqB//99gK5iIERFZETmv2PJBw7F4wA/q5M9y3rF+Kxeiaue2quQ9mZecX6xO7RFYteoAnJ2dsGLlt+jbt77eYRERxRt165ZA5y41ERwcjI4dpsHb23aqzTIRIyKyQue378akRq1xac8BODo54Yt+PdFr8SykyJxR79Bsjr9/IFp9OQkzpm9S16dO64oJE9rrHRYRke5SpPDAvN/6qMtTp2zE/v0XYUtYvj4WsHw9EcVnJRrUQYNBXyOheyL4eHnhx/ot8eb5S73DsknffdcU48a/T8IWL96Frl1mIDAwSO+wiIh0sXrNYDRpUhaXLt1B8WL94OcXAGvA8vVERKSc2LhZVVZ89O9NuHp4oGzzxnqHZLMmTFijht5I8tW+fTVs/HOoOucYEZGtad26skrCAgIC1YmbrSUJiwomYkRENuDVo8fYMWehuly2RWM4OjvrHZLNkp6whg3GwMfHD7VrF8Ou3WPV8BwiIluRIUMKzPjlf+ryyBErVIVZW8REjIjIRpzfuUclZO7Jk6FonZp6h2PTNm8+iWpVf8Dz514oWTInDh6aiCxZUusdFhFRnLOzs8OChX2RJEkiHD16BT/+uAa2iokYEZGNCA4MwsHfV6vLFdq20Dscm3fs2FWULzcIt28/Qc6c6dWJnwsWzKJ3WEREcapnzzqoXr2wGhXQvt1UBAUFw1YxESMisiFH1/4JPx9fpMuZHTlKl9A7HJt39eo9lC0zEOfPeyJt2mTYt38CKlcuoHdYRERxQn50+nFiR3X524ELcP36A9gyJmJERDbE18sbJzb+rS5XZK9YvPDw4QtUqjgY+/ZdROLEbtiydSSaNi2nd1hERLHKwcEei5d8DVdXF2zffgazZm2BrWMiRkRkYw4sW6VOnJm3YjmkyppZ73AIwOvXb/F5rWFYu/YwXFycsHLVt+jV6wu9wyIiijWDBzdDqVK58OrVG3Tu9DM0jWfQYiJGRGRjnt25h8v7DqnL5Vs10zsc+kBKN7do/iNm/boZ9vb2mPFLd4wZ01bvsIiIYqxo0WwYOqyluty712zcv/9c75DiBSZiREQ2aN/Slepv8fp1kNCDpdPjC+mp7NVrFoYOWaquf/9Dc8yf/5Ua0kNEZIkSJHDGkqX94eTkiNWrD+L33/fpHVK8wW92IiIbdOPEady/cg0urglRplkDvcOhUMaO/QNdu8xAUFAQOnaqgfUbhiBhQhe9wyIiirIxY9ogb95MePToJXr2mKV3OPEKEzEiIhu1f+kq9bfcl01h7+igdzgUyvz529G40Tj4+vqhbt0S2LlrDJIlc9c7LCKiSKtUKT/6ff3+xz75cUnOnUj/YSJGRGSjzmzZAa9nz5EkdSoUqllN73AoDJs2HUeN6kPx4oU3ypTJrU78nClTSr3DIiL6JHf3hFi4qJ+a8/rbvG34++8TeocU7zARIyKyUUEBATi8ap26zFL28dfhw5dRofwg3L37FLlzZ8Chw5OQPz+rXRJR/DZ1ahdkyZIaN28+Qv/+8/UOJ15iIkZEZMOO/LEeAX5+yJQ/L7IWKah3OBSOy5fvqhM/X7x4G+nTJ8f+AxNQoUI+vcMiIgpTvXol0alzTVWAqEP7qXjzxlfvkOIlJmJERDbszYuXOP3XNnW5Ytv3pYUpfpJyzxUrDMKBA5eQJEkibNs+Co0aldE7LCKiEFKk8MDceb3V5ck/rcfBg//oHVK8xUSMiMjG7V/2vmhH/qoVkSx9Wr3DoQi8evUWtWoOw4YNR1VJ6NVrvkP37rX1DouIyGj2nF5InTopLly4hWHDlusdTrzGRIyIyMY9+vcmrh4+BnsHB5Rv3VzvcOgT3r3zR7Om4zF3zlY1Cf7XWT0xcmRrvcMiIkKbNlXQuHFZ+PsHoF3bKepE9RQ+JmJERIT9H07wXKpRPbi4ueodDn1CUFAwunefiZEjflfXhw5riTlzevHEz0SkmwwZUmDGL/9Tl0eOWIFz5zz1Dine4zc2ERHh6qFjeHzzFhIkckPJRvX0DociaeTIFejRfaY68XPXbp9jzdrBasgiEZE52dnZYcHCvkic2A1HjlzBxIlr9Q7JIjARIyIiaJpmnCtWoXUz2Nnz34OlmDNnK5o1naCGLDZoUBo7do5G0qSJ9A6LiGxI7951Ub16Ybx9+w7t201Rvfb0afxPS0REyqlNW/D21Wskz5Ae+atU0DscigIp3lGzxlC8fPkG5crlxf4DP6phQkREcS1XrgyY8GN7dfnbgQvx778P9Q7JYjARIyIiJeCdnzqvmGApe8sjJaKlvP29e8+QL18mHDo8EXnzZtI7LCKyYo6ODliytD8SJnTB9u1nMGvWZr1DsihMxIiIyOjQyrUICgjEZ8UKI0Pe3HqHQ1F06dIdlCv7rToBdMaMKXHg4I8oWzaP3mERkZUaPLgZSpTIoXrjO3f6We9wLA4TMSIiMvJ6+gxnt+1Ulyu1Y6+YJbp79ykqlB+Ew4cvq7liMmesfv1SeodFRFamWLHsGDK0hbrcu9dsddJ5ihomYkREFGYp+0I1q8EjVUq9w6FoePHCGzWqD8WmTcfVkKG16wajS5eaeodFRFZCqrMuXvI1nJwc8ccfB7FixT69Q7JITMSIiCiEe/9cxY1TZ+Dg5IjyXzbVOxyKJl9fPzRuNBYL5m+Hg4MD5s7rg6FD2ctJRDE3dmxbNQf14cMX6NnjV73DsVgWl4j17NkTnp6e8PX1xdGjR1GiRIlw182bNy/WrFmj1pfSzH379v1oneHDh6vbTNvly5fj+FUQEcVv+5e8L2VfpllDOCdMoHc4FE1SQrpLlxkYM/p9L+fIUa0xc2YP2PP0BEQUTZUrF8DX/Ruqy106T1c98BQ9FvVN3Lx5c0yZMgUjR45E0aJFce7cOWzbtg0pU4Y9dMbV1RU3b97Ed999h4cPwy+lefHiRaRJk8bYypcvH4evgogo/ru09wCe3b0H18QeKFavtt7hUAwNG7YcvXvNQnBwMHr0rINVfwyCi4uT3mERkYVxd0+IhYv6qctz52zFli2n9A7J4mmW0o4eParNmDHDeN3Ozk67d++eNmjQoE/e19PTU+vbt+9Hy4cPH66dOXMmRnG5u7trQv7qvY3Y2NjYYqtVaN1cm3zhiDboz5Xq+1bveNhi3po0Kav5vlunBWubtD17x2uJE7vpHhMbG5vltPnzv1LfH9f/nau5uSXQPR7E0xbZ3MBiesScnJxQrFgx7Nz5vpqXkGGEcr1MmTIxeuwcOXLg/v37uHHjBpYtW4aMGTNGuL6zszPc3d1DNCIia3N8/V/w9X6DVFkzI1f50nqHQ7Fg7drD+LzWMLx+/RaVKuXHvv3jkS5dMr3DIiILINVXO3aqoXrWO7Sfhrdv3+kdksWzmEQsRYoUcHR0xOPHj0Msl+synDC6jh07hg4dOuDzzz9Hjx49kDVrVhw4cACJEiUK9z6DBw+Gl5eXsUkSR0Rkbfx8fHBs3Z/qciWe4Nlq7Nt3EZUqfocHD56jYMGsOHR4EnLlyqB3WEQUj6VMmRhz5/VWl3+atA6HDv2jd0hWwWISsbiydetWVdDjwoUL2L59O+rUqYMkSZKo+WjhGT9+PDw8PIwtffr0Zo2ZiMhcDv6+GsFBQchZpiTS5MimdzgUS86fv6VO/Hz16j1kzpwKBw/9iFKlcukdFhHFU7Nm90SqVElw4cItNeeUbCwRe/bsGQIDA5E6deoQy+X6o0ePYu15Xr9+jWvXriF79uzhruPv7w9vb+8QjYjIGr188AgXdr0/P0zFNu9P3EnW4fbtJyhfbhCOHbuK5Mk9sGv3WNSpU1zvsIgonmnXrioaNy4Lf/8AtGs7Bf7+gXqHZDUsJhELCAjAqVOnUK1aNeMyOzs7df3IkSOx9jxubm7Ili1bhFUWiYhsyf4l70ufF/2iJhIlS6p3OBSLnj/3QrWqP2Dz5pNwdXXBho1D0KHDf/9nici2ZcqUEj9P76Yujxj+O86d89Q7JKtiMYmYkNL1Xbt2Rbt27ZA7d27MmjVLJU4LFy5Uty9evBjjxo0LUeCjUKFCqkmBDRlCKJcl0TKYNGkSKlasiMyZM6uiH+vXr0dQUBBWrFihy2skIopvbp27gDsX/oGTiwvKNm+kdzgUy3x8/NCwwRgsWrQLjo4OWLCwHwYPbqZ3WESkM+nwWLCwLxIndsPhw5cxadI6vUOySpoltV69emm3bt3S3r17p8rZlyxZ0njbnj17tIULFxqvZ86cWQuLrGdYZ8WKFdr9+/fV4929e1dd/+yzz+KkRCUbGxubpbYitWuoUvYj9v6tOTo76x4PW9y0cePaqdLU0qZP76bZ29vrHhMbG5s+7auv6qnvAu83q7Xs2dPqHg8sqEUhN9A/WEtvTMTY2Nisvdk7OmhDd2xQyViJhl/oHg9b3LU+feppgUEb1QHYylWDNGdnR91jYmNjM2/LnTuD9tZnjfoe6N69tu7xwMKa1Z1HjIiI9BMcGISDK9aoyxVZyt6qzZixCa2+nKQm5jdvXh5bto6Eh4er3mERkZnIEOXFS/ojYUIXbN16CrNnb9E7JKvFRIyIiCLl6JqN8PPxRbqc2ZGjFKvrWbM//jiI2p+PgJeXD6pUKYi9+8YjTRoWaiGyBd9/3wwlSuTAixfe6NJ5ut7hWDUmYkREFCm+Xt44+edmdbkCS9lbvT17zqNypcF49OglChf+TJ34OUeOdHqHRURxqFix7Bgy9P2oh149Z+HBgxd6h2TVmIgREVGk7V+2Sv3NV7k8UmTOqHc4FMfOnr2JcmUH4vr1B8iaNTUOHpqofiknIuuTIIEzliztr4Ymrly5H6tWHdA7JKvHRIyIiCLt2e27uLT3oLrMEzzbBk/Pxyhf7lucOHEdKVMmxu494/D558X0DouIYtm4ce2QJ09GPHjwHL17zdY7HJvARIyIiKJk/9L3J3guXr8OEnp46B0OmcHTp69Rtcr3auK+m1sCbPxzCNq2raJ3WEQUSypXLoB+XzdQl7t0nqHmh1HcYyJGRERR8u/xU3hw9TpcXBOidNP6eodDZvL27Ts0qD8GS5fugZOTo6qqNnBgY73DIqIYkqqoCxf1U5fnzN6ifnAh82AiRkRE0Z4rVr5VM9g7OugdDplJQEAgOrSfip8mrVPXf5zYEVOmdIGdnZ3eoRFRNE2d1hWZM6fCjRsP8c03C/QOx6YwESMioig7s3kHvJ+/QJLUqVCoRlW9wyEz0jQN3367EAP6/6auy3CmZcsHwNnZUe/QiCiKGjQojY4dqyM4OBjt201VPd9kPkzEiIgoygL9/XF45Vp1mSd4tk1Tp25E61Y/qRM/f/llJfz193C4uyfUOywiiiQpvjNnbi91edLEdTh8+LLeIdkcJmJERBQth/9YjwA/P2QqkBdZChfUOxzSwYoV+1D3i1Hw9vZB9eqFsWfveKRKlUTvsIgoEubM7a0+r+fPe2L48OV6h2OTmIgREVG0vHnxEqf/3q4uV2zLUva2aufOs6hS+Xs8efIKRYtmw6HDE5EtW1q9wyKiCLRvXw0NG5ZWPdrt2k6Bv3+g3iHZJCZiREQU46IdBapVQrL0PPi2VadP30C5st+qyf6ShEkyVqxYdr3DIqIwZMqUEj9P76YuDxu6HOfP39I7JJvFRIyIiKLt0fUbuHbkOOwdHFDuy6Z6h0M6kiRMkrFTp/5Vw5327B2HGjWK6B0WEZmQCqdSql5K1h869A9++mm93iHZNCZiREQUI/s+nOC5VOP6cHF11Tsc0pEMT5Rhijt2nEGiRAnx19/D0KpVJb3DIqIPvvqqHqpUKYg3b3xVlUSplkj6YSJGREQxcvXgUTzxvI2E7olQslFdvcMhnckBnhTw+P33ferEz8uWf4Ovv26gd1hENi9PnowYP6G9uvzNgAW4efOR3iHZPCZiREQU4/NK7V/6fq5YhTbNYWfPfy22Tk783LbNZEybulFdnzylCyZN6sQTPxPpxNHRAYuXfI0ECZyxZcspzJ27Ve+QiIkYERHFhpObNsPntReSZ0iPfJUr6B0OxZMEvX//3/DtwAXq+oBvGqkDQeklIyLz+uGH5ihePAdevPBGl87T9Q6HPmAiRkREMRbwzg9HVm9Qlyu2Yyl7+o8UA5Dy2NJL1qZNFfy5aSjc3BLoHRaRzZAE7Ich77+Xe/b4FQ8fvtA7JPqAiRgREcWKgyvWICggENmKFUGGvLn0DofikWXL9qB+vdF4+/YdatUqit17xiFlysR6h0Vk9WQo4pKl/dXQRDkB+x9/HNQ7JDLBRIyIiGKF15OnOLd9l7pcsW1LvcOheGbbttOoWuV7PH36GiVK5MDBQxORNWtqvcMismrjx7dD7twZ8ODBc/TuNVvvcCgUJmJERBRr9i15X8q+cK3q8EiVUu9wKJ45ceI6ypf7Fp6ej5EjRzocOjwJhQt/pndYRFapatWC6NvvfcXSzp2m4+XLN3qHRKEwESMiolhz758ruHnqLBycHFGuZRO9w6F46Pr1ByhXdiDOnr2JNGmSYu++8eqAkYhiT+LEburEzWL2rM2qR5riHyZiREQUq/Z/OMFzmWYN4ZTARe9wKB569OglKlcajN27z8HDwxWbt4xAixastkkUW6b93BUZM6bEv/8+wDffvK9cSvEPEzEiIopVF/ccwPN79+GWJDGK1autdzgUT3l5+aBO7RFYteoAnJ2dsGLlt/jqq3p6h0Vk8Ro1KoP27ashKCgI7dtNhY+Pn94hUTiYiBERUazSgoNxYPlqdblimxY8iS+Fy98/EK2+nIQZ0zep69N+7obx49vrHRaRxUqVKglmz+mlLk/8cS2OHLmid0gUASZiREQU646v34R3b94i9WdZkKtcKb3DoXh+4ue+fefi+8GL1fVB3zVVc1uk3DYRRc3ceb3VqSFkDuaIESv0Doc+gYkYERHFOr+3Pji27k91maXsKTImTFiDjh2mITAwSA2r2rBxCFxdOceQKLI6dKiG+vVLwc8vQA1JlJOoU/zGRIyIiOLEwd9XIzgoCLnKlkKa7CxRTp+2ePEuNGwwRs1pqVOnOHbtHovkyT30Doso3sucOZUa2iuGDV2GCxdu6R0SRQITMSIiihMv7j/Exd37jXPFiCJj8+aTqFb1Bzx/7oVSpXLh4KEf1UEmEYVN5uHKcF6pQHrw4D+YPHmD3iFRJDERIyKiOC9lX7RuLSRKllTvcMhCHDt2FeXLDcLt20+QK1cGHD4yCQULZtE7LKJ4qW/f+qhcuQDevPFFh/ZTERwcrHdIFElMxIiIKM54njmPOxf/gZOLC8o0b6R3OGRBrl69h7JlBuL8eU+kTZsM+/ZPQKVK+fUOiyheyZMnI8aNb6cuD+g/HzdvPtI7JIoCJmJERBSn9i9dpf6WbdEYDk5OeodDFuThwxeoVHEw9u27iMSJ3bBz1xh18udWrSqxkAfZPKksumRpfyRI4KyG9M6bt03vkCiKmIgREVGcOrd9F149fgKPFMlRtE4NvcMhC/P69Vt8XmsYfv99HxwcHPD558WwbPk3ePhoiZoXU716Ydjb83CGbM+QIS1QrFh2NZ+yS+fpeodD0cBvLiIiilPBgUE4tGKNulyBRTsoGqQcd5vWPyFnjm4YOeJ33LjxEO7urqrM/fYdo3H7zgJMnNgRBQpwHhnZhhIlcuD7H5qryz17zMKjRy/1DomiwU7OpRidO9J/3N3d4eXlBQ8PD3h7e+sdDhFRvJPQwwNDd2yAi2tC/NqpF26cOK13SGThypTJjbZtq6B5iwpIlszduFzmlC1bukf1oD148ELXGIniQsKELjh9ZpoqZLN8+V60bTNZ75AomrkBe8SIiCjO+Xp54eSfm9XlSjzBM8WCI0euoGfPWUiXth0aNRyLtWsPq56zggWzYuKkTrhzdyG2bR+Fdu2qIlGihHqHSxRrJkxor5Kw+/efo0/v2XqHQzHAHrFYwB4xIqJPS5klE77btEqVVv6xXgs8u3NP75DIyiRJ4obmzSugdZvKqFAhn3G5nCB6/fojWL5sL3bsOIOgIJb3JstUrVoh7Ng5Rl2uVXOY2p8p/mGPGBERxStPb93BP/sOqcIKnCtGceHVq7eYO3crKlX8Dtk+64JhQ5fh2rX7qsJi69aVVcXFu/cWYcqULihSJJve4RJFiVQOXbCwr7r868y/mYRZAfaIxQL2iBERRU6OUsXR/bcZ8PPxxegaDeDrxe9MMk9hA5lP1qJlRaRMmdi4/NKlO1i+bA+WL9+Hu3ef6hoj0acsWvy1Gmp7/foDFCn8lerpJcvODZiIxQImYkREkTdg7VKky5kdf035BXsWLtc7HLKx8y7VqlUUbdpWQYMGpdT5lwz27Dmvhi6uWXMIXl4+usZJFFrjxmWxZu1gBAUFoUL5QTh69KreIZEtDk3s2bMnPD094evri6NHj6JEiRLhrps3b16sWbNGra9pGvr27RvjxyQiopg58OEEz+VbNYO9o4Pe4ZANCQwMwt9/n8CXLSciTeq26txLkoCJKlUK4rf5X6nzk61Y+S2++KKEStyI9JY6dRLMntNLXf5xwlomYVZGs5TWvHlz7d27d1qHDh20PHnyaHPmzNFevHihpUyZMsz1ixcvrk2cOFFr0aKF9uDBA61v374xfsywmru7uybkr97biI2NjS2+N0dnZ23E3r+1yReOaIU/r657PGxsGTOm1L77rql28dJMLVjbZGyPnyzTpk/vppUokUP3GNlst23YOETtj6fP/Kw5OTnqHg8bYjM30D/YyLajR49qM2bMMF63s7PT7t27pw0aNOiT9/X09AwzEYvJY0ZjY7OxsbGxAVrNHp1VIvbV8t90j4WNzbQVLZpNmzKli/bw0ZIQSdnlK7O0IUNaaFmypNY9RjbbaR07Vlf7n++7dVr+/Jl1j4cNsZobWMzQRCcnJxQrVgw7d+40LpPhhnK9TJkyZn1MZ2dnNfbTtBERUeQd/mMdAv39kblgPmQpVEDvcIiMTp++gf79f0OG9B1Qp/YIdcJcKYog520aNboNbnr+hn37J6Br11qqXD5RXMmSJTWm/dxVXR46ZCkuXrytd0gUyywmEUuRIgUcHR3x+PHjEMvlepo0acz6mIMHD1YT8Azt/v370Xp+IiJb9eb5S5z+e7u6XKEtS9lT/CPnGtu69RTatpms5pN1aD8VO3eeVefBk3OUzZnbGw8fLcXqNYPRoEFpODk56h0yWRE7OzssXNQP7u6uOHDgEqZM2ah3SGTLiVh8Mn78eFUFxdDSp0+vd0hERBZn39KV6m/B6pWRNG30flAjMoc3b3yxZMlu1KwxFJkydsS3Axfg/HlPuLg4oUmTsli/4Qc8eLgYv/7aA2XK5NY7XLIC/frVR6VK+eHt7aN+BJAfAMj6WEwi9uzZMwQGBiJ16tQhlsv1R48emfUx/f39VSlK00ZERFHz6PoNXDt6AvYODqqCIpElePDgBX76aT0KF/oKhQv1weSf1uPBg+dIntwD3XvUwaHDk3D937kYMaIVsmVLq3e4ZIHy5s2EsePaqcv9v54PT8+QI7fIelhMIhYQEIBTp06hWrVqIbpt5fqRI0fizWMSEVHk7V/yvlesVJP6cHF11Tscoig5f/4WBg5cgEwZO6neMuk1k94zScCGDf9SJWSSmPXoUUclakSfIkNclyztr85x99dfJzB//vsh3GS9NEtpUmre19dXa9eunZY7d25t9uzZqtR8qlSp1O2LFy/Wxo0bZ1zfyclJK1SokGr3799XpezlcrZs2SL9mLFZGYWNjY2NLWSTSrWD/lypKiiWb9VM93jY2GLaXF1dtFatKmmbt4zQAgI3GKsu+vmv19Zv+EFr0qSs5uLipHucbPGzjRrVWu0vT54u11KnTqJ7PGyIVrPK8vXSevXqpd26dUud+0tKz5csWdJ42549e7SFCxcar2fOnFkLi6wX2ceM5Y3NxsbGxhaqlWneSCVigzev1uzs7XWPh40ttlqaNEm1fv0aaCdPTQtRCv/FyxXa3Lm9tQoV8qkfI/SOky1+tFKlchmTd0nY9Y6HDdFukc0N7D5coBiQ8vVSPVEKd3C+GBFR1DgnTIChOzbCNbEHFvYdhIu79+sdElGczPtp27YKWrWuhIwZUxqX37r1GMuX7cWyZXtx9eo9XWMk/SRM6IIzZ39GzpzpsWzZHrRrO0XvkMgMuQETsVjARIyIKGa+6NcDVTu3w42TZ/Brx556h0MUZ2QuulTDk6SsSdNy8PD4b27kiRPXsWzpHqxcuR9Pn77WNU4yr+nTu6F3n3q4d+8ZChbojVev3uodEsUAEzEzYiJGRBQziVOnxA9b1sHByRFTmrfH/cvX9A6JyCy9IPXqlUCbtlXx+edF4ejooJYHBgZh27bTKinbuPEY3r3z1ztUikPVqxfG9h2j1WUp+iLnqyPLFtncwGKqJhIRkfV6/fgpzu3YrS5XbNtS73CIzMLX1w9//HEQ9euNQvp07dH3q7k4fvyaSsi++KIEVqz8Fo8eL8X8+V+hSpWCqjeNrEuSJG5YsLCvujzzl7+YhNkY9ojFAvaIERHFXMZ8edBv5QIEBQRiTK1G8Hr6TO+QiHSRK1cGtGlTGa3bVEaWLP+d6/Tu3af4ffk+NYfo0qU7usZIsWPxkv5qmOq1a/dRtEhf+Pj46R0SxQIOTTQjJmJERLGj9+LZyFq0EHbMXYitM+bqHQ6RrqQHrFy5POpAvVnz8kiSJJHxtjNnbqihiytW7MejRy91jZOip0mTsli9ZjCCgoJQvtwgHDt2Ve+QKL4PTXR0dFQnQs6XL19MYyQiIgph39L3J3gu26wRHF1c9A6HSFeapuHgwX/wv//NRNo07dCs6Xhs3HgUAQGBKFIkGyZP6YK79xZi85YRaN26Mlxd+ZmxFKlTJ8Gs2b3U5Qnj1zAJs1FRTsQCAwNx584dODi8n1BKREQUW6R0/fN7D+CWNAmK1/tc73CI4g0/vwCsXXsYjRqORbq07dGr5ywcOXJFHY99/nkxLF02QM0nW7T4a9SoUQT29iwDEJ/NndcHKVJ44PTpGxg16v0PUGSbonySsk6dOml//fWXljRpUt1PmBYfGk/ozMbGxhZ7rWLbluoEzwM3/K57LGxs8b1ly5ZWGz78S+3a9TkhThp97/4ibdKkTlrBgll0j5EtZOvUqYZ6j3x812p582bSPR42WNYJnU+fPo3s2bPDyckJt2/fxtu3Ic91UKxYMdgSzhEjIoo9Lm6uGLbzTyRI5Ia53b/G1UNH9Q6JyCKUKZMbbdpUQfMW5ZE8uYdx+fnznuqk0b//vg/37z/XNUZblzVrapw9Nx3u7q74ZsB8TJmyQe+QyNKKdQwbNizC20eNGgVbwkSMiCh21f+2Lyq1bamSMEnGiCjynJwcUadOcbRpWwV165aAi4uTWh4cHIzdu8+rpEyGOb5546t3qDZFhovu3jMWFSvmx759F1Gt6g/qPSHrw6qJZsREjIgodiXLkA6D/16tDlwmNmyFxzc89Q6JyGLPU9WsWXmVlFWo8F+hNSmTvmHDUVV5cceOMwgKYkIQ1wYMaIRJP3WCt7cPChX8CrduPdY7JLLkRKxo0aLIkyePunzp0iWcPWubJ6FjIkZEFPvaTx2PgtUr4+iajVg9coLe4RBZPDknWevWlVRSJucqM3j8+CVWrtivEjNJ0KRsvuHk0fLnv8v//TWcW/rT64a+33/LP3V/03Wi91yRv3/Y64YVY/TuL72SY8e1U3+7dJ6OBQt2RPNdJNh6IpYyZUqsXLkSlStXxqtXr9SyJEmSYM+ePWjZsiWePbOtk3AyESMiin1yPjE5r1iAnx9G12iIty/f/78hopgrUSKHmk/W8suKSJkysd7h2IxNm46jQf3ReodBlpyISRL22WefoV27drhy5YpaJj1jixcvxr///otWrVrBljARIyKKG/1WLkDGfHmw5Ze52Dlnod7hEFkdR0cH1KpVVPWSlSyZU/XiaNp/5zGTZrj8/q/pZS2cdUOv89/yT68b9nObLo/uc8f2a4nq43l7+eCHH5bi2TOvGL5rZNOJmPSCVa9eHSdPngyxvESJEti+fTuSJk0KW8JEjIgobhT9oiZaTxgJr6fPMKZWYwQFBOgdEhERUazkBtE6259Mng4I45+hLOMJBImIKLac27Ybrx8/hUfKFCj8eXW9wyEiIoo10cqadu/ejZ9//hlp06Y1LkuXLh2mTp2KXbt2xV50RERk04ICA3FwxRp1WcrZExER2XQi1rt3b9XVduvWLTUnTJqnp6da1qdPn9iPkoiIbNaR1Rvg7/sO6fPkRLbiRfQOh4iIKFY4RudO9+7dU6XrZZ5Y7ty51bLLly+zN4yIiGKdr5cXTv65GWVbNEbFdi1x4+QZvUMiIiKKsSgX63B0dISvry8KFy6szh1GLNZBRBTXUmbJhO82rUJwcDAm1G2B53fv6R0SERGReYt1BAYG4s6dO3BwcIjqXYmIiKLl6a07+Gf/IVUQqmKb5nqHQ0REpM8csbFjx2LcuHE2V6aeiIj0c2DZKvW3RMMvkMA9kd7hEBERmX+OmBTryJ49Ox48eIDbt2/j7du3IW4vVqxYzKIiIiIK5dqRE3h4/QbS5siG0k0aYO+i5XqHREREZN5EbMOGDdF/RiIiomjav3QVWoz6HuVbNcX+pSsRHBSkd0hERETmScRkbpimaViwYAHu378fvWclIiKKhtN/b0Odvt2RNG0aFKxeGWe3sVovERHZyByxoKAgDBw4UFVPJCIiMqdAf38c+WO9ulyhbQu9wyEiIjJvsY7du3ejUqVK0X9WIiKiaDq0aq1KyLIUKoBMBfPpHQ4REVG0RKtba8uWLZgwYQIKFCiAU6dOfVSsY9OmTdGLhoiI6BPePH+J05u3o2TDuqjUtiWWDhyqd0hERERxf0Jnw/DE8Mj8MVsbtsgTOhMRmVfanNnxzdqlCAoMxLjaTfHq0WO9QyIiIorbEzobCnaE12wtCSMiIvN7eO1fXD96Eg6Ojijfqpne4RAREUVZlBKxv//+W2V2BoMGDULixImN15MlS4ZLly5FPQoiIqIo2rd0pfpbukl9OCdMqHc4REREcZeI1apVCy4uLsbr33//vUq+DKQ3LFeuXFGLgIiIKBquHDiMp7fuIKGHO0o2+kLvcIiIiOIuEbOzs4vwOhERkbnInOQDy/9Qlyu0bgE7+2iNticiItIF/2sREZHFOrFxM3y8vJAiUwbkrVRO73CIiIjiJhGTXx+lhV5GRESkB39fXxxds1Fdrti2pd7hEBERRVqUShzKUMRFixbBz89PXU+QIAFmz55tPI+Y6fwxIiIiczj0+xpUavclspcoivS5c+L+lWt6h0RERBS7PWKLFy/GkydP8Pr1a9WWLVuGBw8eGK/LbUuWLInKQxIREcXIq8dPcH77bnW5QpsWeodDREQUdyd0ppB4QmciIn1lzJ8X/VbMR2BAAMbUbATvZ8/1DomIiGyUe1ye0JmIiCg+uXvxH3ieOQ9HJyeUa9lE73CIiIg+iYkYERFZhf0fTvBcpllDOHLOMhERxXNMxIiIyCpc3L0fL+4/RKJkSVGsbi29wyEiIrKuRKxnz57w9PSEr5QsPnoUJUqUiHD9pk2b4vLly2r98+fPo3bt2iFuX7hwobEsv6Ft2bIljl8FERHFtuCgIBz4/f0JniuyaAcREcVzFpWINW/eHFOmTMHIkSNRtGhRnDt3Dtu2bUPKlCnDXL9MmTJYsWIF5s+fjyJFimDDhg2q5cuXL8R6knilSZPG2L788kszvSIiIopNx9dtwru3b5Em+2fIVbaU3uEQERFZRyLWv39/zJs3T53LTHq5unfvDh8fH3Tq1CnM9fv27YutW7fip59+wpUrVzBs2DCcPn0avXv3DrGenBft8ePHxvbq1SszvSIiIopN7968xfH1f6nLPMEzERHFZxaTiDk5OaFYsWLYuXOncZkMI5Tr0vMVFlluur6QHrTQ61euXFklYJKs/frrr0iWLFmEsTg7O6uylKaNiIjih4PLVyM4OBi5y5dG6s+y6B0OERGRZSdiKVKkgKOjo0qYTMl1GU4YFln+qfWlx6xdu3aoVq0aBg0ahEqVKqmhivb24W+awYMHq3MDGNr9+/dj/PqIiCh2PL93H5f2HFCXK7TlXDEiIoqfLCYRiyurVq3Cpk2bcPHiRWzcuBF169ZFyZIlVS9ZeMaPH69O0GZo6dOnN2vMREQUuVL2xevWhluSxHqHQ0REZLmJ2LNnzxAYGIjUqVOHWC7XHz16FOZ9ZHlU1hdSkfHp06fInj17uOv4+/urs2SbNiIiij9unjqLu/9cgVMCF5Ru1lDvcIiIiCw3EQsICMCpU6fUEEIDOzs7df3IkSNh3keWm64vatSoEe76Qnq3kidPjocPH8Zi9EREpFevWLmWTeDg6Kh3OERERB/RLKU1b95c8/X11dq1a6flzp1bmz17tvbixQstVapU6vbFixdr48aNM65fpkwZzd/fX+vfv7+WK1cubfjw4Zqfn5+WL18+dbubm5s2ceJErVSpUlrmzJm1qlWraidPntSuXr2qOTs7Rzoud3d3TchfvbcRGxsbG9v75uDoqA3b9ac2+cIRrVjdz3WPh42NjY3NNpp75HMD/YONSuvVq5d269Yt7d27d9rRo0e1kiVLGm/bs2ePtnDhwhDrN23aVLty5Ypa/8KFC1rt2rWNtyVIkEDbunWr9vjxY5WgeXp6anPmzDEmdnGwsdnY2NjYzNiqdWmvErGvVy3SPRY2NjY2Ntto7pHMDew+XKAYkPL1Uj1RCndwvhgRUfzhmtgDQ3dshHPCBJjZsSdunjyjd0hERGTl3COZG1jMHDEiIqKo8nnthZObtqjLlVjKnoiI4hEmYkREZNUOLFul/uatXAHJM2bQOxwiIiKFiRgREVm1J563cfngEdjb26NC62Z6h0NERKQwESMiIqu3f8n7UvYlG9VFAvdEeodDRETERIyIiKzftSPH8fD6Dbi4uqJ04/p6h0NERMREjIiIbGuuWLlWTWHv4KB3OEREZOOYiBERkU049fd2vHnxEsnSpUX+apX0DoeIiGwcEzEiIrIJgX5+OPzHenW5UtuWeodDREQ2jokYERHZjMMr1yLQ3x9ZChdApgJ59Q6HiIhsGBMxIiKyGd7PX+DMlh3qckX2ihERkY6YiBERkU3Z96GUfcEaVZAkTWq9wyEiIhvFRIyIiGzKw2v/4vqxk3BwdET5L5vqHQ4REdkoJmJERGSzpexLN20A54QJ9Q6HiIhsEBMxIiKyOf/sO4Snt+8ioYc7SjT8Qu9wiIjIBjERIyIim6NpGg4s/0NdrtC6Oezs7PQOiYiIbAwTMSIiskknNvwNHy8vpMycEXkqltM7HCIisjFMxIiIyCb5+/ri2Jo/1eWKbVvoHQ4REdkYJmJERGSzDv6+GkGBgchRqjjS5cqhdzhERGRDmIgREZHNevX4Cc7v2KMus1eMiIjMiYkYERHZtP1L35/guUjtGnBPnkzvcIiIyEYwESMiIpt258I/uHX2AhydnVG2ZRO9wyEiIhvBRIyIiGzevg+9YmWbN4Kji4ve4RARkQ1gIkZERDbv4q59ePHgIRIlS4piX9TUOxwiIrIBTMSIiMjmBQcF4dDva9TlCm1YtIOIiOIeEzEiIiIAR9f9CT8fH6TNkQ05y5TUOxwiIrJyTMSIiIgAvPN+g+Pr/1KXK7ZrqXc4RERk5ZiIERERfXBg2R8IDg5GnvJlkCprZr3DISIiK8ZEjIiI6IPn9+7jn70H1GXOFSMiorjERIyIiMjEvqWr1N/i9WrDNbGH3uEQEZGVYiJGRERk4ubJM7j3z1U4J0yAMs0a6R0OERFZKSZiREREoez/cILncl82gYOjo97hEBGRFWIiRkREFMrZrTvx+slTJE6VEoU+r6Z3OEREZIWYiBEREYUSFBiIQyvXqssV27KUPRERxT4mYkRERGE4unoDAt75IWPe3PisWGG9wyEiIivDRIyIiCgMb1+9xsm/tqjL7BUjIqLYxkSMiIgoHAc+lLLPV6UCkmdIr3c4RERkRZiIERERhePxzVu4cvAo7O3tUb51M73DISIiK8JEjIiIKBKl7Es2qosEidz0DoeIiKwEEzEiIqIIXD18DI/+vYkEbm4o2bie3uEQEZGVYCJGRET0CfuXvZ8rVqFVc9g7OOgdDhERWQEmYkRERJ9w6q9tePPiJZKlT4v8VSvqHQ4REVkBi0vEevbsCU9PT/j6+uLo0aMoUaJEhOs3bdoUly9fVuufP38etWvX/midkSNH4sGDB/Dx8cGOHTuQPXv2OHwFRERkaQL9/HBk9QZ1maXsiYjI5hKx5s2bY8qUKSpxKlq0KM6dO4dt27YhZcqUYa5fpkwZrFixAvPnz0eRIkWwYcMG1fLly2dc59tvv8VXX32F7t27o1SpUnj79q16TBcXFzO+MiIiiu8OrVyLwIAAZC1SEBnz59U7HCIisnB2ADRYCOkBO3HiBPr06aOu29nZ4e7du5gxYwZ+/PHHj9ZfuXIl3NzcUK/ef5Orjxw5grNnz6JHjx7quvSETZ48WTXh4eGBx48fo0OHDli16v2cgE9xd3eHl5eXuq+3t3csvVoiIopvWo4ZihIN6uDM5u1YNmi43uHYHKlaaWcvvyHbwd7e7v1lOzkesFeX7QyX7eQ2O3UZHy7LKQiEWu9T65pcVusa7hfGuqEfQz2uiksexxDjp9eV5fYml43PZ7z8YV2YxBXRuh+9ho/vF/r1BgUG4uWDh3h29z5e3LuP5/cewNeLxzVEURXZ3MARFsLJyQnFihXD+PHjjcs0TcPOnTtVz1dYZLn0oJmS3q6GDRuqy1mzZkXatGnVYxjIRjt27Ji6b3iJmLOzc4geM9nYRERk/Q4sW6USsYI1qyLJlJl49fiJ3iFZHacELkiZORNSZc2MVFne/02ZRVomuLgm1Ds8m+Pj5YXnd98nZZKcvU/SHuD5vft49egJgoOC9A6RyGJZTCKWIkUKODo6qt4qU3I9d+7cYd4nTZo0Ya4vyw23G5aFt05YBg8ejBEjRkT7tRARkWW6f+Ua/j1xGtlLFEW5Vk3x99Rf9Q7JYiVOnRKpsmYxSbYyqZYsXdooPU5wcLD8MgstWIOmBasfacO6LON/tOAPy9TyMC5Hcl25PVgePzicdfHhsQy3f1hXM17+sK56Lg3BhnXlR2ZZTz2G4bLpuu+XyXOH+byyrnpu09s/PO8nXo+s55Qggdr+yTOmR/IM6eCRMgVcPTzgms8DGfPl+WjbBwUE4uXDRyopk0TtfcL2PlF7dvce/N76xNr+QmSNLCYRi0+kV860p016xO7fv69rTEREZL4TPEsiVrppA+yYvRD+vr56hxT/e7ckyZIerg8Jl1x3cXUN935vX77CE8/beHLrjvr79Nb7yy8fPkZwUOB/SQ7FKeeECZAsfTqVlCXLkB4pMqZHsgxyPb2qIOrk4oIUmTKoFt77qBI0SdQ+9KoZLr9+8pTvIdk8i0nEnj17hsDAQKROnTrEcrn+6NGjMO8jyyNa3/A39GPIdZlHFh5/f3/ViIjI9vyz7xCe3bmnDj6L16+Nw6vWwdZ5pEqJ1IYk68OQQkm8Iurdkt4UOSh/IkmWJFued1SyJUnX21evzRo/hc3f9506mbm00GSOmUeqFCopk0QtecYMHxK294mae/JkcEuaRLVMBT4ubiOFb17efxhGonYPL+49hJ8Pe9PI+llMIhYQEIBTp06hWrVq2Lhxo/FLQK7/8ssvYd5HCnPI7T///LNxWY0aNdRyIWXwHz58qNaRCoyG3i2pnjhr1iyzvC4iIrIs8iv+geWr0GjwAFRs0wJH/livhnhZO0cX6d3K+D7RMkm2ZFkCN7dw7ydJ1fteLendumXs5ZKD7+BAzi+yVLLPv378VLWbpz7+8Vp6PJNlSPshUUuvhjtKkpYiQ3okTZ8Wjk5OxuGoYfF+/sI4Fy1ksnYfXk+e2cRnjqyfxSRiQoYDLl68GCdPnsTx48fRr18/VRVx4cKF6na5TYYIfv/99+q6JGD79u1D//798ffff6Nly5YoXrw4unXrZnzMadOmYciQIbh+/bpKzEaPHq0qKUqZeyIiorAcX/83Pu/VTR1E5q5QFpf3H4I19W6ZzttKleV94pUkbWpj5cHQpNqeHCS/T7ZCDilk75Ztkh6th9duqBaaVG5MnCpliJ4008vSiyY9atIyF8r/0f0D/Pzw8sEjNQ/tfbIm89PuvS8ocv+B6skjsgQWlYj98ccf6pxho0aNUsU0ZPjg559/jidP3letypQp0/tJux9Iz1erVq0wZswYjBs3TiVbUjHx0qVLxnUmTpyokrm5c+ciSZIkOHjwoHpMPz8/XV4jERHFfzIv7OjaP1GlY2tUatvS4hKx971bGVQ1wpDVCTNF2Lvl89rrfaKlkq0PQwpv3VFJmCRjRJHtVX716LFqN06eCfM0BWoe2odhju+TtPc9a0nTplFz0ww9s2HxevrM2Iv2vnDIf+X45Tai+MKiziMWX/E8YkREtidJmtT4fssaODg64qcmbfHw2r+Ib6Tq3X/ztv4rlpE0XZoIe7fk4DVEoYwPvVxSfIFIT/YODqriZoqMGf5L1D5UeZTLrok9Iry/9JZJr1nouWkqUbv/EIH8IZ7MmBswEYsFTMSIiGxT20mjUfjz6ji+4S+sGjpWlxgcnZ2RQuZumQ4n/JB4Sc9ChL1bJr1ahp4u9m6RJUvo4W6s8mjakyaX5ccT+eEkIjLnLcS8NOlVu/sAz+7dw5vnL832OsiyMREzIyZiRES2KVPBfOi7/DcE+vtjTM1GqsBAXHFPkfxDspUFKbP+V50wabq04fZuycl25YAydLEMufzmBQ8qybbYOzogaZo0SJ7xQzl+0+GPGdMjoXuiCO/v5+P7oTft43L8L+4/RFBAgNleC1lHbmBRc8SIiIjikzvnL+HWuQvIUqgAyrZojG2//hbz3q1MGT7q2ZLLER0k+nh5mSRb/w0plLkxPDgkek+qdBp6uYATH90uwxr/G+r4vhdNJWoZ06veNBfXhEibI5tqHz12cDC8njz9MB/NpNrjhyIiHNZLYWGPWCxgjxgRke0qVKsa2v00RvWGSa+Y9I59ilSDU8lWqEIZcvLciHq35Ff30IUy5C97t4jilgxplLmV/1V5/FCO/0NZ/oiK3Ih3b97i4fUbWD9uMu5fuWa2uEkfHJpoRkzEiIhsu3iAFO2Qam6rho3D8fWb1HIHJydj75ZpoQz5G1Hvlq+X90cl4OUve7eI4i8puW/akxZ6bppp7/W87l/jzoV/dI2X4hYTMTNiIkZEZNsqd2iNegN64+XDR+pXb0m8kqVPq5K0CHu3THu2PszhYkEAIusiQ44lIWs2/DtkLVpI9Y791rM/PM+c1zs0iiNMxMyIiRgRkW1L4J4Iw3ZuhIura4jlvt5vQlYlNPRu3bnH3i0iG+OcMCE6/zIJ2UsWU4U/FvQZiH+Pn9I7LIoDTMTMiIkYERHlKlsKOUqXwLO7994nX56347SKIhFZHqcELug4bQJylSuNgHd+WNh3EK4ePqZ3WBTLmIiZERMxIiIiIorsUMV2k8ciX+XyqrjP4v4/4J99B/UOi3TIDcIuzURERERERLFOJV9fD8b5HXtUUtZh6ngUqF5Z77BIB0zEiIiIiIjMKCgwEEsHDsXpzdvh4OSItpNGo0idmnqHRWbGRIyIiIiIyMykeurvg0fi+Ia/1HnKWo0fjhINv9A7LDIjJmJERERERDrQgoPxx7BxOLJ6gzqZe8vRQ1C6WUO9wyIzYSJGRERERKQTTdOwZtSP2L9slbrebNggVGjdXO+wyAyYiBERERER6Wzjj9OwZ8Eydbnhd1+jSsfWeodEcYyJGBERERFRPPDX1JnYPnuBuly3f2/U6N5J75AoDjERIyIiIiKKJ7bNnIfN02ery5/36oraff6nd0gUR5iIERERERHFI7vmLcafk6ary9W7dUC9b/roHRLFASZiRERERETxzL4lK7Bu7E/qcuX2rdD4h29gZ2end1gUi5iIERERERHFQ4dWrsUfI8YjODgY5Vo2QdNhg2Bnz8N3a8F3koiIiIgonjq29k+sHDJGnQC6dNMG6lxj9g4OeodFsYCJGBERERFRPHZq0xYsHzQcQYGBKF6/NlpPGAF7RyZjlo6JGBERERFRPHd22y4sGTAEgQEBKPx5dbSfPBYOTk56h0UxwESMiIiIiMgCXNy9D4v6focAPz/kr1oJHX+eAEcXF73DomhiIkZEREREZCEuHziMBX0Gwt/3HfJUKIvOMybCKQGTMUvERIyIiIiIyIJcO3IC83r2h5+PD3KWKYmus6bCxdVV77AoipiIERERERFZmJsnz2But37w9X6DbMWLoNucaUiQyE3vsCgKmIgREREREVmgW+cuYHaXPvB57YUshQvgf/OmI6GHh95hUSQxESMiIiIislD3/rmCWZ17482Ll8iUPy96zJ8Bt6RJ9A6LIoGJGBERERGRBXtw9Tp+7dQLXs+eI33unOi5YCbckyfTOyz6BCZiREREREQW7vENT8zs0AOvHj9BmuyfoefCX5E4dUq9w6IIMBEjIiIiIrICz27fVcnYi/sPkSprZvRaNAtJ06XROywKBxMxIiIiIiIr8eLeA/zasSee3bmH5BnSq56x5Bkz6B0WhYGJGBERERGRFXn58BFmduyJJ563kSxdWvRa+KvqIaP4hYkYEREREZGV8XryFDM79sDD6zfUXDHpGZO5YxR/MBEjIiIiIrJCb56/xKxOvXD/8jVVRVGqKUpVRYofmIgREREREVmpt69eY1aX3rhz4R91frHu82cgY/68eodFTMSIiIiIiKybr5c3ZnftA8/T5+Dq4YHu86YjS+GCeodl85iIERERERFZOb+3Ppjb/Wv8e/wUEiRyQ7c5U5GtRFG9w7JpTMSIiIiIiGyAv68vfus1AFcPHYWLqyu6/joFucqW0jssm8VEjIiIiIjIRgS888OCrwbh0t6DcErggk4zJiJPxXJ6h2WTLCYRS5o0KZYtW4bXr1/j5cuX+O233+Dm5hbhfVxcXPDLL7/g2bNn8Pb2xpo1a5AqVaoQ62ia9lFr0aJFHL8aIiIiIiJ9BPr7Y/HXg3F+xx44Ojuj47QJKFC9st5h2RyLScSWL1+OfPnyoUaNGqhbty4qVqyIuXPnRnifqVOnol69emjWrBkqVaqEdOnSYd26dR+t16FDB6RJk8bYNmzYEIevhIiIiIhIX0GBgVg6cChOb94OBydHtJ00GkVq19A7LJujxfeWO3duTRQrVsy4rFatWlpQUJCWNm3aMO/j4eGh+fn5aU2aNDEuy5Url3qcUqVKGZeJBg0axCg+d3d39TjyV+9txcbGxsbGxsbGxhbZZmdvr7UY/YM2+cIRbdK5Q1qJBnV0jwkW3iKbG1hEj1iZMmXUcMRTp04Zl+3cuRPBwcEoVSrsCYbFihWDs7OzWs/g6tWruH37tno8UzNnzsTTp09x7NgxdOzY8ZPxyOO6u7uHaERERERElkYLDsYfw8bhyOoNsLe3R8sxQ1G6aQO9w7IJjrAAMlzwyZMnIZYFBQXhxYsX6rbw7uPn56fmlJl6/PhxiPsMHToUu3fvho+PD2rWrIlff/0ViRIlwowZM8KNZ/DgwRgxYkSMXxcRERERkd6kRsKaUT8iwM8PFdu0QLPh36m5Ywd/X613aFZN1x6x8ePHh1ksw7TlypUrTmMYM2YMDh8+jLNnz2LixImqDRw48JNxe3h4GFv69OnjNEYiIiIiori28cdp2LNgmbrcaHB/VO7QWu+QrJquPWKTJ0/GokWLIlzn5s2bePTo0UfVDh0cHJAsWTJ1W1hkuVRNTJw4cYhesdSpU4d7HyHDE4cNG6aGH/r7+4e5jiwP7zYiIiIiIkv119SZCPD3R83unVBvQG84ujhj55yFeodllXRNxKSsvLRPOXLkiCpfX7RoUZw+fVotq1q1qhrHKolTWGQ+mSRL1apVM1ZKzJkzJzJnzqweLzyFCxdWQx6ZaBERERGRLdo2c54qcV/nq+6o3bsbHJ2dsHVGxNXKKXo0S2ibN2/WTp06pZUoUUIrW7asdvXqVW358uXG29OlS6ddvnxZ3W5Y9uuvv2q3bt3SKleurBUtWlQ7dOiQaobb69atq3Xu3FnLly+fli1bNq179+7amzdvtBEjRsRJZRQ2NjY2NjY2NjY2S2mV2n2pqilKqzegj+7xwEJaFHID/YONTEuaNKlKvLy8vLRXr15p8+fP19zc3Iy3Z86cWb3gSpUqGZe5uLhov/zyi/b8+XOVYK1du1ZLnTp1iBL4p0+fVo/p7e2tnTlzRuvWrZtmZ2cXVxubjY2NjY2NjY2NzWJauZZNjMlYo+8HRPk42RabeyRzA7sPFygGpHy9l5eXKtzh7e2tdzhERERERLGmVJP6aDpskJoWdHTNRlVhUYrqUcxyA4s4jxgREREREenj2No/sXLIGAQHBalzjMm5xuwdHPQOy+IxESMiIiIiogid2rQFywcNR1BgIIrXr41W44fD3pHJWEwwESMiIiIiok86u20XlgwYgsCAABSpXQPtfhoLBycnvcOyWEzEiIiIiIgoUi7u3odFfb9DgJ8fClSrhA7TxsPR2VnvsCwSEzEiIiIiIoq0ywcOY0GfgfD3fYe8Fcuh8y+T4JTARe+wLA4TMSIiIiIiipJrR05gXs/+8PPxQc4yJdF11lS4uLrqHZZFYSJGRERERERRdvPkGczt1g++3m+QrXgRdJszDQkSuekdlsVgIkZERERERNFy69wFzO7SBz6vvZClcAH8b950JPTw0Dssi8BEjIiIiIiIou3eP1cwq3NvvHnxEpny50WP+TPgljSJ3mHFe0zEiIiIiIgoRh5cvY5fO/WC17PnSJ87J3oumAn35Mn0DiteYyJGREREREQx9viGJ2Z26IFXj58gTfbP0HPhr0icOqXeYcVbTMSIiIiIiChWPLt9VyVjL+4/RKqsmdFr0SwkTZdG77DiJSZiREREREQUa17ce4BfO/bEszv3kDxDetUzljxjBr3DineYiBERERERUax6+fARZnbsiSeet5EsXVr0Wvir6iGj/zARIyIiIiKiWOf15ClmduyBh9dvqLli0jMmc8foPSZiREREREQUJ948f4lZnXrh/uVrqoqiVFOUqorERIyIiIiIiOLQ21evMatLb9y58I86v1j3+TOQMX9e2DomYkREREREFKd8vbwxu2sfeJ4+B1cPD3SfNx1ZCheELWMiRkREREREcc7vrQ/mdv8a/x4/hQSJ3NBtzlRkK1EUtoqJGBERERERmYW/ry9+6zUAVw8dhYurK7r+OgW5ypaCLWIiRkREREREZhPwzg8LvhqES3sPwimBCzrNmIg8FcvB1jARIyIiIiIiswr098firwfj/I49cHR2RsdpE1CgemXYEiZiRERERERkdkGBgVg6cChOb94OBydHtJ00GkVq14CtYCJGRERERES6CA4Kwu+DR+L4hr/g4OiIVhNGoESDOrAFTMSIiIiIiEg3WnAw/hg2DkdWb4C9vT1ajhmK0k0bwNoxESMiIiIiIl1pmoY1o37E/mWr1PVmw79D+VbNYM2YiBERERERUbyw8cdp2LNgmbrcaHB/VO7QGtaKiRgREREREcUbf02die2zF6jL9Qb0RvX/dYQ1YiJGRERERETxyraZ87B5+mx1uXbvbvi8TzdYGyZiREREREQU7+yatxh/TpquLtfo1hH1BvSBNWEiRkRERERE8dK+JSuwbuxP6nLlDq3Q6PsBsLOzgzVgIkZERERERPHWoZVr8ceI8QgODkb5L5ui6bBBVpGMMREjIiIiIqJ47djaP7FyyBh1Amg5x5ica8zewQGWjIkYERERERHFe6c2bcHyQcMRFBiI4vVro9X44bB3tNxkjIkYERERERFZhLPbdmHJgCEIDAhAkdo10O6nsXBwcoIlYiJGREREREQW4+LufVjU9zsE+PmhQLVK6DBtPBydnWFpmIgREREREZFFuXzgMBb0GQh/33fIW7EcOv8yCU4JXGBJmIgREREREZHFuXbkBOb17A8/Hx/kLFNSVVO0JEzEiIiIiIjIIt08eQZzu/XDo39vYvuv82FJpAC/pncQls7d3R1eXl7w8PCAt7e33uEQEREREdkUO3t7aMHBsKTcgD1iRERERERk0bR4koRFhcUkYkmTJsWyZcvw+vVrvHz5Er/99hvc3NwivE/Xrl2xZ88edR9N05A4ceJYeVwiIiIiIiKbSMSWL1+OfPnyoUaNGqhbty4qVqyIuXPnRngfV1dXbN26FePGjYvVxyUiIiIiIoopLb633Llza6JYsWLGZbVq1dKCgoK0tGnTfvL+lSpVUvdPnDhxrD6uobm7u6vHkb96bys2NjY2NjY2NjY2NujWIpsbWESPWJkyZdSwwVOnThmX7dy5E8HBwShVqpTZH9fZ2VlNwjNtREREREREkWURiViaNGnw5MmTEMuCgoLw4sULdZu5H3fw4MGqEoqh3b9/P9oxEBERERGR7dE1ERs/frwqohFRy5UrF+IbiVvKURpa+vTp9Q6JiIiIiIgsiKOeTz558mQsWrQownVu3ryJR48eIVWqVCGWOzg4IFmyZOq26Iru4/r7+6tGRERERERkcYnYs2fPVPuUI0eOqDLzRYsWxenTp9WyqlWrwt7eHseOHYv288fV4xIREREREVn8HLErV65gy5YtmDdvHkqUKIGyZcvil19+wcqVK/Hw4UO1Trp06XD58mV1u0Hq1KlRqFAhZM+eXV0vUKCAui7JV2Qfl4iIiIiIKC5oltCSJk2qLV++XPPy8tJevXqlzZ8/X3NzczPenjlzZlUmUkrVG5YNHz5cC0v79u0j/bixWaKSjY2NjY2NjY2Njc26W2RzA7sPFygGpHy9VE+Uwh3e3t56h0NERERERPE8N7CIoYlERERERETWhIkYERERERGRLVVNtMZuSCIiIiIisl3ukcwJmIjF4sa+f/++3qEQEREREVE8yREimiPGYh2x5OrVqyhevHi4tx8/fhwlS5aM0m1hLf/UMnnDJSFMnz59nBcOieg1xfb9P7Uut2/M7h+ZdaOyHS1h+4YXT3zbvuHdFtntzu376XVisg9z+356HW7fmK/L7Rv9+3L7xu19uX3DJzE9ePAggjXYIxZrAgMDI3zjg4ODw709vNvCWh7ZZXI9rnfEiF5TbN//U+ty+8bs/pFZNyrb0RK2b3jPHd+2b3i3RXa7c/t+ep2Y7MPcvp9eh9s35uty+0b/vty+cXtfbt/wRSYOFuuIJTNnzoz27eHdFtbyyC4zh5g+b1Tuz+0bt/ePzLpR2Y6WsH1j+tzm2r7h3RbZ7c7t++l1YrIPc/t+eh1u35ivy+0b/fty+8btfbl9Y4ZDE60Mz2kWt7h94xa3b9zi9o1b3L5xi9s3bnH7xi1u37jlbqHblz1iVsbPzw8jRoxQfyn2cfvGLW7fuMXtG7e4feMWt2/c4vaNW9y+ccvPQrcve8SIiIiIiIjMjD1iREREREREZsZEjIiIiIiIyMyYiBEREREREZkZEzEiIiIiIiIzYyJGRERERERkZkzEbFTOnDlx5swZY/Px8UGDBg30DsuqZMmSBbt378alS5dw/vx5uLq66h2SVfH09MS5c+fU/ivbmWJfwoQJcevWLUyaNEnvUKxK4sSJceLECbXvXrhwAV26dNE7JKuTIUMG7NmzR33/yvdE06ZN9Q7J6qxbtw4vXrzA6tWr9Q7FKnzxxRe4cuUKrl27hs6dO+sdjtVZF4/3Vylfz2bDzc3NTXv69Knm6uqqeyzW1Pbu3auVL19eXU6aNKnm4OCge0zW1Dw9PdW+q3cc1tzGjBmjrVy5Ups0aZLusVhTs7e31xImTKguy/fuzZs3tWTJkukelzW1NGnSaIUKFVKXU6dOrd27d4//42K5VapUSatbt662evVq3WOx9CbHB1evXtXSpUun/q9duXKF3wmwjf2VPWKE+vXrY9euXapXjGJH3rx5ERAQgIMHD6rrL1++RFBQkN5hEUVa9uzZkTt3bmzZskXvUKxOcHAwfH191WUXFxfY2dmpRrHn0aNHqidMPH78GM+ePUOyZMn0Dsuq7Nu3D97e3nqHYRVKliypem8fPHiAt2/fqu/dmjVr6h2WVdkXT/dXJmLxVIUKFfDnn3/i/v370DQtzGGDPXv2VMOz5B/60aNHUaJEiWg9V/PmzbFq1SrYkrjevjly5MCbN2/Uc5w6dQqDBw+GLTHH/iuPK1+sx48fR6tWrWBLzLF9f/rpJ5vbb825fWV44tmzZ3Hv3j019PP58+ewJeb8H1e0aFE4ODiobW0rzLl9KebbO126dOq+BnI5ffr0Zos/vqtgxfszE7F4ys3NTf2a16tXr3CTpylTpmDkyJHqn4ysu23bNqRMmdK4jmH+QeiWNm1a4zru7u4oW7YsNm/eDFsS19vX0dFRfXHIF0OZMmVQo0YNVK9eHbbCHPtv+fLlUbx4cdWj+/3336NAgQKwFXG9fWWbyjyF69evwxaZY/99/fo1ChcujKxZs6ofElKlSgVbYq7/cUmTJsWSJUvQrVs32BJzbV+Kve1Ntrt9dR8fyRZxEw0aNAix7OjRo9qMGTOM1+3s7NQY+EGDBkXpsdu0aaMtXbpU99dobdu3dOnS2tatW43Xv/nmG9X0fq3Wsn1Dt4kTJ2rt27fX/bVay/YdN26cdufOHTUPT+aPvnr1Shs6dKjur9Vatm/oNnPmTK1Jkya6v1Zr28bOzs7avn371P85vV+jNW5fw7yb+DbnxhK3d5kyZbR169YZb586dar25Zdf6v5a4mOLyf4cH/dX9ohZICcnJxQrVgw7d+40LpOuWrkuvS9RYYvDEs2xfaUimvzCnSRJEjX3o2LFirh8+XIcRm1b21cqUCZKlMj4S1nVqlXV+HqKne0rPYyZMmVSvTXffPMN5s2bh9GjR8dh1La1feW7wbD/enh4qO+Hq1evxlnMtvo/btGiRaqi6rJly+IoUssUm8cQFDvbW4bY58+fXw1RlP9ptWvXVj06ZP37s6PeAVDUpUiRQg19kwnIpuS6TK6PLDkAkAmiTZo0iYMobXv7SmEOOZjdv3+/SsS2b9+Ov//+O44itr3tmzp1aqxfv15dlrkfkiicPHkyTuK11e8HirvtmzlzZsydO9dYpGPGjBm4ePFiHEVsm9u4XLlyaNGihTp1SMOGDdWytm3bcjvH4nfEjh07UKhQIZU43L17F82aNVNzcyjq21uOGQYMGKBOuWBvb4+JEyeqUusUe/tzfN1fmYjZMC8vL6RJk0bvMKzW1q1bVaPYJxNyZX4Nxb3FixfrHYLVkR7zIkWK6B2GVTt06JD6kYbijsx9ptizadMm1ci29lcOTbRAUoY3MDBQ9QqYkutSspdihts3bnH7xi1u37jF7Rv3uI3jFreveXF7x61nFr59mYhZIDk/lZREr1atmnGZDG+R60eOHNE1NmvA7Ru3uH3jFrdv3OL2jXvcxnGL29e8uL3jVoAVbF/dK4awfdzkzOqFChVSTfTr109dzpgxo7q9efPmmq+vr9auXTstd+7c2uzZs7UXL15oqVKl0j12S2jcvty+lty4fbl9Lb1xG3P7WlPj9ub2RfSb7gGwhdGkxGZYFi5caFynV69e2q1bt7R3796p0p0lS5bUPW5Lady+3L6W3Lh9uX0tvXEbc/taU+P25vZFNJvdhwtERERERERkJpwjRkREREREZGZMxIiIiIiIiMyMiRgREREREZGZMREjIiIiIiIyMyZiREREREREZsZEjIiIiIiIyMyYiBEREREREZkZEzEiIiIiIiIzYyJGREQUSZ6enujbt6/eYRARkRVgIkZERPHKwoULsX79esRHJUqUwNy5c82S8Gmaptrbt29x/vx5dO7cOcqPI/dv0KBBnMRIREQxw0SMiIhsnqOjY6TWe/bsGXx9fWEOQ4cORZo0aZA/f34sW7YMv/32Gz7//HOzPDcREcU9JmJERGRR8uXLh82bN8Pb2xuPHj3CkiVLkDx5cuPttWrVwoEDB/Dy5UuVOG3atAmfffaZ8fbMmTOrnqLmzZtj7969KrFq3bq1sSduwIABePDggbrvL7/8EiJJCz00UR5HeqrWrVuneq6uXbuGevXqhYhXrstyeZ7du3ejXbt26n6JEyeO8HXK63v8+LF6zokTJ+L58+eoUaOG8fbixYtj+/btePr0KV69eqVeS5EiRULEKjZs2KCez3Bd1K9fH6dOnVIx3bhxA8OGDYODg0M03g0iIoouJmJERGQxJHmRZObMmTMqEZEeotSpU+OPP/4wruPm5oYpU6ao26tVq4bg4GCVYNnZ2YV4rAkTJuDnn39Gnjx5sG3bNrWsSpUqyJYtm/rbvn17dOjQQbWIDB8+XD1/wYIFVYK4fPlyJE2aVN2WJUsWrFmzRiVDhQoVwpw5czB27NgovWaJu3Hjxuox/f39jcvd3d2xePFilC9fHqVLl8b169fV8ydKlMg4jFJI/NKzZrgu60vyKq89b968+N///qfW+eGHH6IUFxERxZzGxsbGxsYWX9rChQu19evXh3nbDz/8oG3dujXEsvTp02siR44cYd4nefLk6vZ8+fKp65kzZ1bXv/rqq4+e19PTU7O3tzcuW7VqlbZixQrjdbm9b9++xuti1KhRxuuurq5qWa1atdT18ePHa+fPnw/xPKNHj1brJE6cONxtIM/z7t07zdvbW/P391frP3v2TMuWLVu497Gzs9Nev36tffHFFyHia9CgQYj1duzYoX333XchlrVu3Vq7f/++7u89GxsbG2yosUeMiIgshvQqSW+VDNsztCtXrqjbpCdLZM+eHb///rsacvf69WvcunVLLc+UKVOIxzp58uRHj3/p0iXVg2bw8OFDpEqVKsKYpJCGgY+Pj3pOw31y5cqFEydOhFj/+PHjkXqtkyZNQuHChVG1alUcPXoUX3/9tXpNBvIcUjhEhj3K0EQvLy/VGxb6dYa1DWUoouk2nDdvHtKlS4eECRNGKjYiIoq5yM1OJiIiigck0ZA5X4MGDfroNkmahNx++/ZtdO3aVc31sre3VwmWs7NziPVlTldoAQEBIa7L3Cq5f0Sic5/IkDlqknhJa9asGS5cuKCSx8uXL6vbZViizI2TOWvyev38/HDkyJGPXmdY21CGU8q8ttDevXsX47iJiChymIgREZHFOH36NJo0aaJ6uYKCgj66PVmyZMidO7dKwg4ePKiWlStXDnq5evUq6tSpE2KZYa5WVNy7dw+rVq3C+PHj0bBhQ+Pr6tmzJ7Zs2aKuZ8iQASlTpgxxP5lTFroIh2xD6akz7V0jIiLz49BEIiKKl0U5ZAidaZNEY+bMmSrZWrFihSrGIdUQa9asiQULFqheKEOlxG7duhmLbkjhDr1IcQ5JDKUwSI4cOVTPlqH4h/ScRYUU15AKjMWKFVPXpThH27Zt1eOXLFlSFQmRoZGmJGGVgiVS0CRJkiRq2ahRo1TlRhmeKMU65P4tWrTA6NGjY+11ExHRpzERIyKieEcSqLNnz4ZoMpxOhh9KT5D08kjpdhmuN23aNDVHSuZ2SXLTsmVLlaxcvHgRU6dOxcCBA3V7HZIINW3aVFU9lLlkPXr0MFZNlKGEUSFDEuU1SyIlpGy+VFKUHq6lS5di+vTpePLkSYj7SCl+KXl/9+5dVWlSyGPUrVtXJbAyf80w/0yGNxIRkflILd+o/SRHRERE0fb999+je/funyyqQURE1o1zxIiIiOKQ9IJJz5OckFl686SHTk4UTUREto2JGBERURySuWFDhgxRc9vu3LmDyZMnq6IbRERk2zg0kYiIiIiIyMxYrIOIiIiIiMjMmIgRERERERGZGRMxIiIiIiIiM2MiRkREREREZGZMxIiIiIiIiMyMiRgREREREZGZMREjIiIiIiIyMyZiREREREREZsZEjIiIiIiICOb1f1iAlPgiVZR5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_network(name, epochs=200, lr=0.01, hidden_layers=2, seed=42, optimizer='SGD', bvalues=bvalues, batch_size=16, sims=1000):\n",
    "\n",
    "    trainloader, inferloader, testloader = sim_dat(bvalues, batch_size=batch_size, sims=sims)\n",
    "\n",
    "    model = make_model(n_inputs=len(bvalues), n_hidden=hidden_layers, n_outputs=1)\n",
    "\n",
    "    # initialize model --> we did this above, but during the exercise, you might be re-running this part of the script several times with different settings. This way we make sure you re-initiate the training and don't continue in the last model\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # initialize wandb\n",
    "    wandb.init(\n",
    "            project=\"AI_for_medical_imaging\", job_type=\"training\", name=name)\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # probe available devices\n",
    "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set default device. If GPU is available, the network will be trained on the GPU. Note that further down in the code, stuff will be sent \".to(device)\" to make sure it is available on the GPU.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    # define the loss of the network (mean square error)\n",
    "    loss_module = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "    # the optimizer determines how strongly to update the network's weights based on the calculated loss.\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        raise NotImplementedError('this optimizer is not implemented yet...')\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # initiate losses to 0\n",
    "        train_loss_f = 0\n",
    "        val_loss_f = 0\n",
    "        # set model to training such that forward passes are remembered (requiered for backpropogating the loss)\n",
    "        model.train()\n",
    "        # loop over all training data\n",
    "        SD_train = 0\n",
    "        sys_train = 0\n",
    "        for x in trainloader:\n",
    "            # reset the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # get data (x[0]) and put the data on the GPU if available\n",
    "            batch = x[0].to(device)\n",
    "            # get the reference f (x[2]) --> note x[1] and x[3] are D and Dp respectively\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            # put the data through the neural network\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            # calculate loss (compare predicted f to the ground trueth)\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            # add found loss to the train loss, to keep track of the loss this epoch\n",
    "            train_loss_f += loss_f.item()\n",
    "            # propogate the loss through the network (calculate d_wights/d_loss)\n",
    "            loss_f.backward()\n",
    "            # update all weights accoording to their derrivatives to the loss.\n",
    "            optimizer.step()\n",
    "            # calculate the standard deviation and systematic error on the trianing data\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "            # add the errors to ultimately calculate their mean over the trianing data. calculating mean SDs goes via the Root Mean Squares. So add SDs squared\n",
    "            SD_train += SD**2\n",
    "            sys_train += sys\n",
    "        # now divide by the total amount of training data to calculate the mean (sys error) and square of mean (SD).\n",
    "        SD_train = np.sqrt(SD_train/trainloader.__len__())\n",
    "        sys_train = sys_train/trainloader.__len__()\n",
    "\n",
    "        # after training, set model to evaluation mode\n",
    "        model.eval()\n",
    "        SD_val = 0\n",
    "        sys_val = 0\n",
    "        for x in inferloader:\n",
    "            batch = x[0].to(device)\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            val_loss_f += loss_f.item()\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "            SD_val += SD**2\n",
    "            sys_val += sys\n",
    "        SD_val = np.sqrt(SD_val/inferloader.__len__())\n",
    "        sys_val = sys_val/inferloader.__len__()\n",
    "\n",
    "        # make b-value data pairs: Note these currently contain the f_ref and f_pred from the trianing data. You may want to swap to validation data once implemented\n",
    "        example_data = [[x, y] for (x, y) in zip(f_ref.cpu().detach().numpy(), f_pred.cpu().detach().numpy())]\n",
    "        # put it in a table\n",
    "        table = wandb.Table(data=example_data, columns=[\"f_ref\", \"f_pred\"])\n",
    "        # tell wandb to plot the table\n",
    "        if epoch % 10 == 0:\n",
    "            wandb.log({\"loss/train\": train_loss_f/trainloader.__len__(), \"loss/val\": val_loss_f/inferloader.__len__(), \"error/random error\": SD_train, \"error/systematic error\": sys_train, \"data_plot epoch \" + str(epoch): wandb.plot.scatter(table, \"f_ref\", \"f_pred\", title=f'epoch{epoch}')})\n",
    "\n",
    "        # print output in terminal. Only useful for debugging when WandB does not work\n",
    "        # print('epoch = ' + str(epoch) + ' train loss =' + str(train_loss_f/trainloader.__len__()) + ' val loss =' + str(val_loss_f/inferloader.__len__()) + ' the systematic error is ' + str(sys_val) + ' and the random error is ' + str(SD_val))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    SD_test = 0\n",
    "    sys_test = 0\n",
    "    test_loss_f = 0\n",
    "    for x in testloader:\n",
    "        batch = x[0].to(device)\n",
    "        f_ref = torch.flatten(x[2].to(device))\n",
    "        f_pred = torch.flatten(model.forward(batch))\n",
    "        loss_f = loss_module(f_pred, f_ref)\n",
    "        test_loss_f += loss_f.item()\n",
    "        SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "        SD_test += SD**2\n",
    "        sys_test += sys\n",
    "    SD_test = np.sqrt(SD_test/testloader.__len__())\n",
    "    sys_test = sys_test/testloader.__len__()\n",
    "\n",
    "    # log test results to wandb\n",
    "    wandb.log({\"loss/test\": test_loss_f/testloader.__len__(), \"error/random error test\": SD_test, \"error/systematic error test\": sys_test})\n",
    "\n",
    "    # print('Test loss =', test_loss_f/testloader.__len__(), 'Systematic error =', sys_test, 'Random error =', SD_test)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return sys_test, SD_test\n",
    "\n",
    "learning_rates = [10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001]\n",
    "\n",
    "sys_errors = []\n",
    "random_errors = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    # print(f\"Training with learning rate: {lr}\")\n",
    "    sys_error, random_error = train_network('test_val_eval_lr', lr=lr)\n",
    "    sys_errors.append(sys_error)\n",
    "    random_errors.append(random_error)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(learning_rates, sys_errors, label='Systematic Error (sys_test)')\n",
    "plt.plot(learning_rates, random_errors, label='Random Error (SD_test)')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Systematic and Random Errors as Function of Learning Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "E.\tPlot the performance (sys_val and SD_val) as function of the width (number of neurons per layer: 5, 10, 20, 50, 100) and depth (number of hidden layers: 1, 2, ..., 8) of the network and add these to the report. Discuss how width and depth may influence the network; if it has this behaviour in your data, highlight it; if not, explain why it may not occur in your dataset.\n",
    "\n",
    "Hint: currently, the width of the network copies the width of the data, so you need to uncouple the input width from the network width by adapting the \"make model\" code.\n",
    "Tip: you only need to plot different widths for 1 depth (e.g. 2) and different depths for 1 width (e.g. 10).\n",
    "Tip: possibly some effects get clearer when more training data is simulated (\"sims\" in data_sim). But also note that having too much training data may hide some of the effects from other exercises, so don't forget to revert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "F.\tTry different batch sizes (1, 4, 16, 64, 128, 516).Explain the behavior of the network you see.What is the effect of having smaller batches? And larger batches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "G.Chose 3 hidden layers, width of 40,  learning rate of 0.1 and batch size of 2. Now train the network for 3000 epochs. At what point in the network fully trained? How do you see this? Does any overfitting occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Second week (on schedule means finish by Wednesday) [if updated: 12-2-2025]\n",
    "H.\tCurrently, the model uses a Relu activation function. Test the effect of different activation funtions on the network performance. Show how well does a sigmoid or ELU work (i.e. what is the effect on performance)?\n",
    "\n",
    "Note, you can either:\n",
    "- adapt the scripts above to program this \"neatly\" as input parameter.\n",
    "- redefine new \"programs\" below that have the new properties you want.\n",
    "\n",
    "Note that in the case of option 1, your programs need to stay backwards compatible, as examiners will need to be able to rerun your code and reproduce your results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "So far, we simualted a small amount of data, as it is easier to show overfitting etc. Note that you may want to simulate somewhat more data for this and the following exercises. This can be achieved by setting sims=100000 for the following exercises\n",
    "\n",
    "I.\tLet the network also predict D and Dp (note x[1] and x[3] are D and Dp respectively). Show the loss curve of D and Dp and explain how you can see that they have been implemented properly/the model is learning them.\n",
    "o\tThe network will need more than 1 output --> tip, use loss_D.backward(retain_graph=True) for the first two losses to remember losses and propogate all 3 losses backward in turn\n",
    "o\tAlternatively, you could train 3 networks simultaniously\n",
    "Note that 0<f<1 on avergae is orders of magnitude larger than D and Dp. To ensure all three losses equally affect the network weights you may want to enlarge the loss of D and Dp by multiplying them with some value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "J.\tUse the sigmoid in the final layer to constrain 0.5e-3 <D< 3.5e-3; 0<f<1; 5e-3<D*<130e-3. Explain how you did this.\n",
    "Note: D, f and D* are in very different parameter value ranges, and hence their RMS is too. A network will focus on the largest loss. You may want to scale the RMS to similar ranges for the network to consider all 3 parameters during optmizing.\n",
    "Also note: You may want to play with hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# For scoring 7.5+\n",
    "So far, you have been working with simulated data (taken care of by Data_loader.py). For such data, we know the ground truth values. However, in vivo, we have no way of knowing the ground truth. How will our network perform? Note that for this exercise you may need ot play with hyperparameters and design choices to train.\n",
    "\n",
    "K.\tUse the network, as trained in (J) and apply it to real-world data which is provided by running “dataval, valid_id, bvalues = hf.load_real_data(eval=True)”.\n",
    "- You will need to export you trained network in the return of the \"train_network\" function\n",
    "- you will need to apply it to the \"dataval\" from hf.load_real_data(eval=True)\n",
    "- you will then want to put the outputs through \"hf.plot_example(np.squeeze(D_out), valid_id,0.003)\", \"hf.plot_example(np.squeeze(f_out), valid_id,0.7)\" and \"hf.plot_example(np.squeeze(Dp_out), valid_id,0.1)\", with the predicted D, f and Dp being D_out, f_out and Dp_out.\n",
    "\n",
    "Note that alongside your plot (the first), also a conventional least squares fit is provided as a reference. Show the resulting parameter maps. How does your approach compare? Why do you think your particular approach would look better/worse?\n",
    "\n",
    "L.\tIdeally, you would train your network on real-world data. However, in this particular case, it is hard to get gold standard references. Luckily, we can use our understanding of physics, and of how stuff “should behave” to work our way around this. You will redesign your network loss, such that it can train on data without any gold standard references! Instead of placing the L2 loss on f_pred v.s. f_ref. Currently, the network is learning to minimize the difference between predicted fpred and the ground truth referene ftrue. In vivo, we may not have these references. To overcome this, we will now introduce a physics-informed loss. Use the IVIM equation [1] to propogate the predictions (D, f and Dp) into the signal space (S). Then, take e.g. the mean-square-error between the predicted signal and the input signal. Note that you will need to use torch functions (instead of numpy functions) to ensure you can backpropogate the loss through the equation into the network. You can train this network on the simulated data from earlier exercises. But it should also be able to train it on the in vivo data from \"datatrain, bvalues = hf.load_real_data(eval=False)\". This ensures that the network is use to looking at \"real\" data. Optimize the network’s training using the real data provided (“test_in_vivo.py”; datatrain). Evaluate the network on the same data as in 1 (data, valid_id, bvalues = dl.load_real_data(eval=True)). How does it perform?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load patient data \n",
      "\n",
      "Patient data loaded\n",
      "\n",
      "Load patient data \n",
      "\n",
      "Patient data loaded\n",
      "\n",
      "training data is 103608 long\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'D_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m### use datatrain to train your network.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m## then test your network using dataval.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m''''if you manage to make predictions of D, f and Dp, the following code will allow you to plot them:'''\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m hf\u001b[38;5;241m.\u001b[39mplot_example(np\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mD_out\u001b[49m), valid_id,\u001b[38;5;241m0.003\u001b[39m)\n\u001b[0;32m     11\u001b[0m hf\u001b[38;5;241m.\u001b[39mplot_example(np\u001b[38;5;241m.\u001b[39msqueeze(f_out), valid_id,\u001b[38;5;241m0.7\u001b[39m)\n\u001b[0;32m     12\u001b[0m hf\u001b[38;5;241m.\u001b[39mplot_example(np\u001b[38;5;241m.\u001b[39msqueeze(Dp_out), valid_id,\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'D_out' is not defined"
     ]
    }
   ],
   "source": [
    "datatrain, bvalues = hf.load_real_data(eval=False)\n",
    "dataval, valid_id, bvalues = hf.load_real_data(eval=True)\n",
    "print('training data is ' + str(len(datatrain)) + ' long')\n",
    "\n",
    "''''your code here'''\n",
    "### use datatrain to train your network.\n",
    "## then test your network using dataval.\n",
    "''''if you manage to make predictions of D, f and Dp, the following code will allow you to plot them:'''\n",
    "\n",
    "hf.plot_example(np.squeeze(D_out), valid_id,0.003)\n",
    "hf.plot_example(np.squeeze(f_out), valid_id,0.7)\n",
    "hf.plot_example(np.squeeze(Dp_out), valid_id,0.1)\n",
    "hf.plot_ref()\n",
    "\n",
    "### you can compare supervised and self-supervised fits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
